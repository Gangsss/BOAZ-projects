{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chankoo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "K = 6\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [5,5,4,3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    W['w_'+str(k)] = np.random.randint(0,high = 5,size=(D,N) ,dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = np.zeros((D,K,N),dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    for d in range(D): \n",
    "        W2[d][k] = W['w_'+str(k)][d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 2, 3, 1, 0, 0, 1, 3, 3, 3],\n",
       "        [4, 2, 4, 1, 0, 1, 0, 3, 1, 4],\n",
       "        [4, 2, 1, 1, 3, 0, 3, 2, 4, 2],\n",
       "        [0, 3, 2, 2, 1, 2, 4, 3, 4, 2],\n",
       "        [1, 1, 4, 3, 1, 4, 4, 2, 3, 4],\n",
       "        [4, 4, 3, 4, 2, 0, 4, 2, 2, 2]],\n",
       "\n",
       "       [[2, 1, 1, 1, 3, 0, 0, 0, 1, 0],\n",
       "        [1, 3, 0, 0, 4, 2, 2, 4, 2, 1],\n",
       "        [2, 4, 3, 4, 0, 3, 1, 4, 1, 1],\n",
       "        [2, 4, 0, 2, 4, 1, 0, 4, 1, 3],\n",
       "        [0, 2, 2, 1, 3, 1, 3, 4, 4, 0],\n",
       "        [1, 0, 1, 3, 3, 2, 0, 3, 0, 1]],\n",
       "\n",
       "       [[3, 1, 1, 2, 4, 1, 3, 2, 4, 0],\n",
       "        [3, 1, 2, 3, 1, 0, 0, 3, 2, 1],\n",
       "        [3, 2, 4, 0, 2, 2, 3, 1, 1, 0],\n",
       "        [2, 2, 1, 3, 4, 3, 3, 1, 2, 2],\n",
       "        [2, 1, 2, 3, 2, 3, 1, 2, 4, 1],\n",
       "        [1, 4, 1, 4, 4, 3, 3, 2, 2, 2]],\n",
       "\n",
       "       [[4, 1, 0, 3, 0, 1, 0, 0, 2, 1],\n",
       "        [1, 1, 3, 4, 0, 1, 4, 3, 4, 4],\n",
       "        [2, 3, 4, 4, 3, 4, 2, 2, 3, 1],\n",
       "        [3, 1, 3, 4, 3, 0, 3, 4, 0, 3],\n",
       "        [2, 0, 1, 2, 3, 0, 4, 4, 4, 0],\n",
       "        [2, 1, 2, 2, 2, 2, 4, 2, 1, 0]],\n",
       "\n",
       "       [[0, 4, 4, 1, 4, 4, 3, 1, 1, 1],\n",
       "        [1, 0, 4, 2, 3, 0, 2, 3, 2, 1],\n",
       "        [2, 0, 4, 3, 1, 0, 1, 0, 0, 2],\n",
       "        [0, 3, 3, 4, 2, 0, 2, 2, 4, 3],\n",
       "        [1, 4, 2, 1, 2, 2, 2, 3, 1, 2],\n",
       "        [0, 2, 1, 3, 2, 4, 3, 0, 1, 3]]], dtype=int16)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [5, 5, 4, 3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRR_Model:\n",
    "    global W2\n",
    "    W = W2\n",
    "    SCORE_SQUARE = False\n",
    "    T = 1000 # max iteration\n",
    "    \n",
    "    K = None # num of aspects\n",
    "    D = None # num of documents\n",
    "    N = None # num of words\n",
    "    \n",
    "    mu = None\n",
    "    sigma = None\n",
    "    sigma_inv = None\n",
    "    delta_square = None\n",
    "    beta = None\n",
    "    \n",
    "    aspect_weight = None # alpha\n",
    "    alpha_hat = None \n",
    "    \n",
    "    aspect_rating = None # S\n",
    "    \n",
    "    ratings = None\n",
    "    \n",
    "    _old_aspect_weight = None # old alpha\n",
    "    _old_aspect_rating = None\n",
    "    _old_beta = None\n",
    "    \n",
    "    def __init__(self,k,d,n,ratings:list):\n",
    "        self.K = k\n",
    "        self.D = d\n",
    "        self.N = n\n",
    "        self.ratings = np.array(ratings,dtype='float64')\n",
    "        \n",
    "        self.mu = np.array(np.random.rand(self.K) * 2.0 - np.ones(self.K) ,dtype='float64')\n",
    "        self.sigma = np.array(np.identity(self.K),dtype='float64')\n",
    "        self.sigma_inv = np.linalg.inv(self.sigma)\n",
    "        \n",
    "        self.beta = (2*np.random.rand(self.K, self.N)-1.0)/10\n",
    "        self.delta_square = np.ones(1,dtype='float64')\n",
    "        \n",
    "        self.alpha_hat = np.random.normal(loc = self.mu, scale= self.sigma.diagonal(),size=(D,K) )\n",
    "        \n",
    "        self.aspect_weight = np.zeros((D,K))\n",
    "        for d in range(D):\n",
    "            self.aspect_weight[d] = np.exp(self.alpha_hat[d])/np.sum(np.exp(self.alpha_hat[d]))\n",
    "            \n",
    "        self._old_aspect_weight = np.zeros((D,K))\n",
    "        self._old_aspect_rating = np.zeros((D,K))\n",
    "        self._old_beta = np.zeros((K,N))\n",
    "    \n",
    "#     def calc_covariance(self,vct):\n",
    "#         '''\n",
    "#         :param vct:\n",
    "#         :return:\n",
    "\n",
    "#         double sum = 0, s;\n",
    "# \t\tfor(int i=0; i<m_k; i++){\n",
    "# \t\t\ts = 0;\n",
    "# \t\t\tfor(int j=0; j<m_k; j++)\n",
    "# \t\t\t\ts += vct[j] * m_sigma_inv[j][i];\n",
    "# \t\t\tsum += s * vct[i];\n",
    "# \t\t}\n",
    "# \t\treturn sum;\n",
    "\n",
    "#         '''\n",
    "\n",
    "#     def calc_det(self):\n",
    "#         return np.linalg.det(self.sigma)\n",
    "\n",
    "#     def calc_sigma_inv(self,scale):\n",
    "#         self.sigma_inv = np.linalg.inv(self.sigma) * scale\n",
    "\n",
    "    def save(self,file_name:str):\n",
    "        print(os.path.join(os.getcwd(), os.path.join('model', file_name)))\n",
    "        with open(os.path.join(os.getcwd(), os.path.join('model', file_name)), 'wb') as fp:\n",
    "            pickle.dump(self,fp)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls,file_name:str):\n",
    "        try:\n",
    "            with open(os.path.join(os.getcwd(),os.path.join('model',file_name)),'rb') as fp:\n",
    "                return pickle.load(fp)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def _set_aspect_rating(self):\n",
    "        self._old_aspect_rating = self.aspect_rating\n",
    "        tmp_aspect_rating = np.zeros((D,K))\n",
    "        \n",
    "        if self.SCORE_SQUARE==True:\n",
    "            for d in range(D):\n",
    "                tmp_aspect_rating[d] = 0.5*np.sum(np.multiply(self.beta,self.W[d]),axis=1)#to avoid negative rating \n",
    "            self.aspect_rating = tmp_aspect_rating\n",
    "        else:\n",
    "            for d in range(D):\n",
    "                tmp_aspect_rating[d] = np.exp(np.sum(np.multiply(self.beta,self.W[d]),axis=1))#to avoid negative rating \n",
    "            self.aspect_rating = tmp_aspect_rating\n",
    "            \n",
    "    def _infer_aspect_weight(self):\n",
    "        for d in range(D): # set the old aspect_weight\n",
    "            self._old_aspect_weight[d] = np.exp(self.alpha_hat[d])/np.sum(np.exp(self.alpha_hat[d]))\n",
    "            \n",
    "        alpha_hat = tf.Variable(self.alpha_hat, name = 'aspect_weight_hat',dtype=tf.float64)\n",
    "        \n",
    "        mu = tf.placeholder_with_default(self.mu,shape=(K),name='mu')\n",
    "        sigma_inv = tf.placeholder_with_default(self.sigma_inv,shape=(K,K),name='sigma_inv')\n",
    "        delta_square = tf.placeholder_with_default(self.delta_square,shape=(1),name='delta_square')\n",
    "        s = tf.placeholder_with_default(self.aspect_rating,shape=(D,K),name = 'aspect_rating')\n",
    "        ratings = tf.placeholder_with_default(self.ratings,shape=(D),name = 'ratings')\n",
    "\n",
    "#        # To get gradient\n",
    "#         preceding_tmp = np.zeros((D,K),dtype='float32')\n",
    "#         for d in range(D):\n",
    "#             preceding_tmp[d] = (((self.ratings - np.matmul(self.alpha_hat_T[0],self.aspect_rating_T[0].T).diagonal())[d]*self.aspect_rating_T[0][d]) )\n",
    "\n",
    "#         preceding = tf.placeholder_with_default(preceding_tmp,shape=(D,K),name='precending')\n",
    "#         grad =  preceding/tf.square(delta) + tf.matmul((alpha_hat-mu),sigma_inv)\n",
    "\n",
    "        loss = tf.square( ratings - tf.linalg.diag_part(tf.matmul(alpha_hat,tf.transpose(s)) ))/(2*tf.square(delta_square)) + 0.5*tf.matmul(tf.matmul(tf.subtract(alpha_hat,mu), sigma_inv),tf.transpose(tf.subtract(alpha_hat,mu)))\n",
    "\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "        train = optimizer.minimize(loss)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for step in range(201):\n",
    "                res = sess.run([alpha_hat,train])\n",
    "                if step % 20 == 0:\n",
    "                    print(step,':')\n",
    "                    print('loss:',sess.run(loss),'\\n') \n",
    "                    print('alpha_hat:',sess.run(alpha_hat),'\\n')\n",
    "        \n",
    "        self.alpha_hat = res[0] # set a new alpha_hat\n",
    "        for d in range(D): # set a new aspect_weight\n",
    "            self.aspect_weight[d] = np.exp(self.alpha_hat[d])/np.sum(np.exp(self.alpha_hat[d]))\n",
    "\n",
    "    \n",
    "    def e_step():\n",
    "        self._set_aspect_rating() # step 1: estimate aspect rating & update\n",
    "        self._infer_aspect_weight() # step 2: infer aspect weight & update\n",
    "    \n",
    "    def _infer_beta(self):\n",
    "        self._old_beta = self.beta\n",
    "        \n",
    "        # 텐서플로까지(beta_rep이 Variable) 한번에 코드짤수있는 방안??\n",
    "        W_beta = np.zeros(D,K,N) # multiply of W & beta\n",
    "        for d in range(D):\n",
    "            W_beta = np.multiply(self.beta,self.W[d])\n",
    "        \n",
    "        \n",
    "        beta = tf.Variable(np.tile(self.beta,self.N).reshape(self.K,self.N), name = 'beta_rep',dtype=tf.float64)\n",
    "        \n",
    "        alpha = tf.placeholder_with_default(self.aspect_weight,shape=(D,K),name='aspect_weight')\n",
    "        # W(K,N) 인메모리??\n",
    "        delta_square = tf.placeholder_with_default(self.delta_square,shape=(1),name='delta_square')\n",
    "        sigma_inv = tf.placeholder_with_default(self.sigma_inv,shape=(K,K),name='sigma_inv')\n",
    "        ratings = tf.placeholder_with_default(self.ratings,shape=(D),name = 'ratings')\n",
    "        \n",
    "        W = tf.placeholder_with_default(self.W,shape=(D,K,N),name='W')\n",
    "        \n",
    "        loss = tf.reduce_sum(\n",
    "                tf.math.divide(\n",
    "                              tf.square(tf.subtract(ratings, tf.reduce_sum(tf.math.multiply(\n",
    "                                                                                  tf.reduce_sum(\n",
    "                                                                                        tf.math.multiply(beta,\n",
    "                                                                                                               W)\n",
    "                                                                                                        ,axis=1) \n",
    "                                                                                                ,axis=1)\n",
    "                                                                                            ,alpha )\n",
    "                                                                          )\n",
    "                                                   )\n",
    "                                       )\n",
    "                ,delta_square) \n",
    "                            )\n",
    "    \n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "        train = optimizer.minimize(loss)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for step in range(201):\n",
    "                res = sess.run([beta,train])\n",
    "                if step % 20 == 0:\n",
    "                    print(step,':')\n",
    "                    print('loss:',sess.run(loss),'\\n') \n",
    "                    print('alpha_hat:',sess.run(beta),'\\n')\n",
    "        \n",
    "            self.beta = res[0] # set a new beta\n",
    "            \n",
    "    \n",
    "    \n",
    "    def m_step(self): # m-step can only be applied to training samples\n",
    "        # updateSigma = false; // shall we update Sigma?\n",
    "        # Step 0: initialize the statistics\n",
    "        # Step 1: ML for \\mu\n",
    "        self.mu = (np.sum(self.mu,axis=0))/self.D\n",
    "        # Step 2: ML for \\sigma\n",
    "        #######################\n",
    "        \n",
    "        # Step 3: ML for \\delta\n",
    "        self.delta_square = np.sum(np.square( self.ratings - np.diagonal(np.matmul(self.aspect_weight, np.transpose(self.aspect_rating)) ))) / self.D\n",
    "        \n",
    "        #Step 4: ML for \\beta\n",
    "        self._infer_beta()\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def em_est(converge:float):\n",
    "#         e_step()\n",
    "#         m_step()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LRR_Model(6,5,10,ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chankoo\\Desktop\\GitHub\\BOAZ-projects\\airbnb-NLP\\model\\test.model\n"
     ]
    }
   ],
   "source": [
    "model.save('test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LRR_Model.load('test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._set_aspect_rating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._old_aspect_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.36106182, 0.99872305, 0.74516358, 1.25071528, 1.42804492,\n",
       "        0.53300072],\n",
       "       [1.02209736, 1.20229705, 0.48964648, 1.07968697, 1.77028983,\n",
       "        0.67562646],\n",
       "       [1.45839343, 0.97014964, 0.53784751, 1.28753277, 1.17611385,\n",
       "        0.62682705],\n",
       "       [1.07398682, 1.30253731, 0.41614316, 0.95925696, 1.31965487,\n",
       "        0.50620148],\n",
       "       [1.93525733, 0.85452814, 0.68011651, 1.4087055 , 1.54593813,\n",
       "        0.47987615]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.aspect_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.36106182, 0.99872305, 0.74516358, 1.25071528, 1.42804492,\n",
       "        0.53300072],\n",
       "       [1.02209736, 1.20229705, 0.48964648, 1.07968697, 1.77028983,\n",
       "        0.67562646],\n",
       "       [1.45839343, 0.97014964, 0.53784751, 1.28753277, 1.17611385,\n",
       "        0.62682705],\n",
       "       [1.07398682, 1.30253731, 0.41614316, 0.95925696, 1.31965487,\n",
       "        0.50620148],\n",
       "       [1.93525733, 0.85452814, 0.68011651, 1.4087055 , 1.54593813,\n",
       "        0.47987615]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.aspect_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._old_aspect_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "loss: [[ 6.67540185  0.33186554 17.10572114  3.0387028   5.17478016]\n",
      " [-0.78297208  2.90871865 17.81861768  3.56717242  3.48067579]\n",
      " [-0.56327276  1.26446139 20.15256008  2.45999157  1.77437776]\n",
      " [ 0.73678194  2.38008916 17.82706461  4.64650374  4.25242305]\n",
      " [ 2.69148048  2.11221372 16.96007197  4.07104423  7.42305305]] \n",
      "\n",
      "alpha_hat: [[ 2.18948722 -1.23016182  1.40811658  0.04839526  1.39406684 -0.7736269 ]\n",
      " [ 0.75857383  0.60420913 -1.0294542  -0.64549924  0.96591075  2.06388357]\n",
      " [ 0.74330791  0.20525221 -1.83325883 -1.23205516 -0.54668929 -0.06188477]\n",
      " [ 0.80443046 -0.33222987 -0.15760771 -1.84938611  1.0045901   1.70899648]\n",
      " [ 0.70187306 -2.12693348  0.12502977  0.17643918  0.95268715  1.9813087 ]] \n",
      "\n",
      "20 :\n",
      "loss: [[ 6.42327835 -0.63930911  4.43095631  1.26644962  2.13853885]\n",
      " [-0.90568666  2.16546415  4.95847844  1.95473634  0.73598803]\n",
      " [-0.18056052  0.61333916  6.32384217  0.58584839 -0.62511692]\n",
      " [ 0.54694322  1.50160749  4.47785882  2.79627459  1.5098177 ]\n",
      " [ 1.90057921  0.76440594  3.74844026  1.99136446  4.66929759]] \n",
      "\n",
      "alpha_hat: [[ 2.18082649 -1.09317204  1.44907475  0.11662089  1.38474508 -0.77275475]\n",
      " [ 0.80991644  0.83779038 -0.96377258 -0.50581261  1.10064771  2.12025394]\n",
      " [ 1.3195685   0.72731233 -1.58708758 -0.64955649 -0.09857309  0.19263561]\n",
      " [ 0.91968574 -0.01679933 -0.07803992 -1.67199554  1.15808132  1.77295961]\n",
      " [ 0.3530412  -2.15732452  0.03491698 -0.01417798  0.65691061  1.88938774]] \n",
      "\n",
      "40 :\n",
      "loss: [[ 6.22423217 -0.93239721  1.31442883  0.65644888  1.46223924]\n",
      " [-1.00879002  2.04507886  1.86257702  1.49567222  0.17831939]\n",
      " [ 0.01857859  0.64311958  3.11693507  0.1218243  -1.16115287]\n",
      " [ 0.40819773  1.32381387  1.16942339  2.21764486  0.89490676]\n",
      " [ 1.48432311  0.27679606  0.15678124  1.16524179  4.15951029]] \n",
      "\n",
      "alpha_hat: [[ 2.14832565 -0.98971057  1.47415176  0.15521643  1.3501918  -0.78310693]\n",
      " [ 0.80120593  0.98676516 -0.93000899 -0.43664302  1.13434607  2.13629931]\n",
      " [ 1.58207897  1.02430476 -1.46029016 -0.35194149  0.0951677   0.31059436]\n",
      " [ 0.95312204  0.1856056  -0.0337521  -1.57552673  1.21165925  1.79684343]\n",
      " [ 0.19775224 -2.11965636  0.0090762  -0.07252797  0.51435274  1.84289864]] \n",
      "\n",
      "60 :\n",
      "loss: [[ 6.05091253 -1.08747167  0.49375846  0.36978694  1.20212491]\n",
      " [-1.11311549  2.01931461  1.09971794  1.33150057 -0.01474407]\n",
      " [ 0.08634683  0.71795014  2.40301611 -0.00862203 -1.36345402]\n",
      " [ 0.27404043  1.26139788  0.30304309  1.98148645  0.6402426 ]\n",
      " [ 1.22815955  0.03693439 -0.93000775  0.76202374  3.9559246 ]] \n",
      "\n",
      "alpha_hat: [[ 2.10993975 -0.90379688  1.49295731  0.18181454  1.30954326 -0.7966697 ]\n",
      " [ 0.76903073  1.09511733 -0.91056811 -0.39878501  1.12780426  2.136055  ]\n",
      " [ 1.69318028  1.20731536 -1.39246527 -0.19460353  0.16677042  0.36258848]\n",
      " [ 0.94699698  0.32702648 -0.00791818 -1.52099474  1.21679038  1.8012124 ]\n",
      " [ 0.12130125 -2.06054376  0.00779999 -0.08016999  0.43473434  1.81498497]] \n",
      "\n",
      "80 :\n",
      "loss: [[ 5.90253971 -1.20174104  0.2366168   0.18700838  1.03624501]\n",
      " [-1.21039811  2.00904109  0.90235143  1.24988409 -0.13383782]\n",
      " [ 0.08963114  0.76402284  2.26601413 -0.06145657 -1.48125228]\n",
      " [ 0.14682837  1.21836114  0.04534907  1.84759173  0.46725086]\n",
      " [ 1.04876833 -0.11265743 -1.3217433   0.51995419  3.79427643]] \n",
      "\n",
      "alpha_hat: [[ 2.0723179  -0.82874595  1.50914093  0.2032977   1.26981457 -0.81040571]\n",
      " [ 0.72906762  1.18220431 -0.89779305 -0.37518219  1.10684129  2.12977578]\n",
      " [ 1.73210798  1.33099687 -1.35402289 -0.10674509  0.18066083  0.38303071]\n",
      " [ 0.92265517  0.43419357  0.00806317 -1.48851089  1.19937977  1.79640018]\n",
      " [ 0.07831961 -1.99762628  0.01554749 -0.06897229  0.38235565  1.79511911]] \n",
      "\n",
      "100 :\n",
      "loss: [[ 5.77726311 -1.29473318  0.12694751  0.04775118  0.90595849]\n",
      " [-1.29660019  2.0054496   0.8478691   1.19784011 -0.22802653]\n",
      " [ 0.06631087  0.78909947  2.25972857 -0.09418736 -1.56409698]\n",
      " [ 0.03040748  1.18236343 -0.05089441  1.75257471  0.3274052 ]\n",
      " [ 0.91146124 -0.22065677 -1.4979576   0.35025164  3.64720217]] \n",
      "\n",
      "alpha_hat: [[ 2.03757673 -0.76168176  1.52399728  0.22221578  1.23320017 -0.82329014]\n",
      " [ 0.687833    1.2566348  -0.8883676  -0.35846398  1.08213191  2.12173403]\n",
      " [ 1.7374111   1.42237443 -1.33045735 -0.05369764  0.16810837  0.38865282]\n",
      " [ 0.89078355  0.5209802   0.01860588 -1.46790299  1.17237864  1.78757141]\n",
      " [ 0.05053889 -1.9373971   0.02620244 -0.05146416  0.34281162  1.77909017]] \n",
      "\n",
      "120 :\n",
      "loss: [[ 5.67202594 -1.37241066  0.0626162  -0.06673095  0.79771895]\n",
      " [-1.37132486  2.00803596  0.8334267   1.1612417  -0.3073309 ]\n",
      " [ 0.03466728  0.80439198  2.28237605 -0.11861199 -1.62651093]\n",
      " [-0.07387829  1.15300855 -0.09781041  1.67842148  0.20904511]\n",
      " [ 0.80078372 -0.30535193 -1.59549724  0.21925722  3.51484288]] \n",
      "\n",
      "alpha_hat: [[ 2.0061284  -0.70123909  1.53794669  0.23946029  1.20009938 -0.8350698 ]\n",
      " [ 0.64789278  1.32236637 -0.88084872 -0.3454455   1.05789662  2.11364249]\n",
      " [ 1.72776042  1.49495013 -1.31463839 -0.01845497  0.14420464  0.38756078]\n",
      " [ 0.85666152  0.59471835  0.02599493 -1.45393564  1.14219079  1.77728397]\n",
      " [ 0.03041952 -1.88204101  0.03736459 -0.03256767  0.31011622  1.76516051]] \n",
      "\n",
      "140 :\n",
      "loss: [[ 5.58371960e+00 -1.43802356e+00  1.69554170e-02 -1.63777816e-01\n",
      "   7.06536865e-01]\n",
      " [-1.43564397e+00  2.01628141e+00  8.32695593e-01  1.13537543e+00\n",
      "  -3.75157409e-01]\n",
      " [ 2.82405356e-03  8.16184636e-01  2.31147129e+00 -1.37027307e-01\n",
      "  -1.67497009e+00]\n",
      " [-1.66263489e-01  1.13051016e+00 -1.25381616e-01  1.61887523e+00\n",
      "   1.07205110e-01]\n",
      " [ 7.09164589e-01 -3.74909278e-01 -1.65821101e+00  1.12318507e-01\n",
      "   3.39781213e+00]] \n",
      "\n",
      "alpha_hat: [[ 1.97781065 -0.64663389  1.55111527  0.25533383  1.17031612 -0.84576264]\n",
      " [ 0.61014193  1.38135423 -0.87459265 -0.33472984  1.03565867  2.10613792]\n",
      " [ 1.71213143  1.55559783 -1.30304072  0.00735861  0.11616241  0.38365784]\n",
      " [ 0.82283343  0.65939623  0.03143137 -1.44388458  1.11191647  1.76678255]\n",
      " [ 0.014734   -1.8320796   0.04811489 -0.01418021  0.28166577  1.75257562]] \n",
      "\n",
      "160 :\n",
      "loss: [[ 5.50961601 -1.49394022 -0.01814075 -0.24724732  0.62946684]\n",
      " [-1.4910281   2.02925465  0.8380235   1.11788923 -0.43357883]\n",
      " [-0.02598507  0.82726706  2.34217879 -0.15020436 -1.71320115]\n",
      " [-0.24771274  1.11451169 -0.14282547  1.57087405  0.01868501]\n",
      " [ 0.63237809 -0.43357969 -1.70244558  0.02206169  3.29537007]] \n",
      "\n",
      "alpha_hat: [[ 1.95231205e+00 -5.97303358e-01  1.56354731e+00  2.69954715e-01\n",
      "   1.14350593e+00 -8.55465884e-01]\n",
      " [ 5.74788251e-01  1.43468897e+00 -8.69293476e-01 -3.25675964e-01\n",
      "   1.01584487e+00  2.09941580e+00]\n",
      " [ 1.69477972e+00  1.60793127e+00 -1.29390219e+00  2.79001877e-02\n",
      "   8.73658032e-02  3.78802553e-01]\n",
      " [ 7.90465197e-01  7.17278516e-01  3.55619541e-02 -1.43630711e+00\n",
      "   1.08299284e+00  1.75665129e+00]\n",
      " [ 2.01976421e-03 -1.78740353e+00  5.81299109e-02  3.01445429e-03\n",
      "   2.56243198e-01  1.74097978e+00]] \n",
      "\n",
      "180 :\n",
      "loss: [[ 5.44743469 -1.54201865 -0.04592715 -0.31969302  0.56430788]\n",
      " [-1.53892834  2.04593337  0.84657339  1.10714718 -0.48421753]\n",
      " [-0.05078919  0.83862104  2.37334456 -0.15884946 -1.74363461]\n",
      " [-0.31945243  1.10429745 -0.15374683  1.53237217 -0.0589058 ]\n",
      " [ 0.56770546 -0.48391026 -1.735375   -0.05574881  3.20613154]] \n",
      "\n",
      "alpha_hat: [[ 1.9293168  -0.55277463  1.57527485  0.28339751  1.11932586 -0.86428812]\n",
      " [ 0.54177033  1.48307991 -0.86478764 -0.3179601   0.998456    2.09349748]\n",
      " [ 1.67766922  1.65394952 -1.28632472  0.04526204  0.05934474  0.37386075]\n",
      " [ 0.76003229  0.76972979  0.03874798 -1.43041829  1.05602374  1.74714325]\n",
      " [-0.00844631 -1.7476784   0.06732629  0.01882145  0.23321567  1.73018375]] \n",
      "\n",
      "200 :\n",
      "loss: [[ 5.39529541 -1.58374134 -0.06819466 -0.38302629  0.50927901]\n",
      " [-1.5806359   2.06538693  0.85692648  1.10184894 -0.52841506]\n",
      " [-0.07161234  0.85040337  2.40450167 -0.1637233  -1.76797405]\n",
      " [-0.38273673  1.09903307 -0.16001606  1.50177367 -0.12743717]\n",
      " [ 0.51317961 -0.52761991 -1.76065578 -0.12382614  3.12856876]] \n",
      "\n",
      "alpha_hat: [[ 1.90854467 -0.5126209   1.58633523  0.29573444  1.09747428 -0.87232863]\n",
      " [ 0.51093146  1.52705839 -0.86097229 -0.31139218  0.98334147  2.08834051]\n",
      " [ 1.66165616  1.69484175 -1.27983534  0.06052306  0.03273651  0.36921808]\n",
      " [ 0.73166851  0.81763486  0.041202   -1.42577372  1.03119975  1.73834694]\n",
      " [-0.01706749 -1.71250473  0.07571623  0.03324106  0.21220639  1.72007101]] \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-c41c103288ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_aspect_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-260-903b511769ad>\u001b[0m in \u001b[0;36m_infer_aspect_weight\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maspect_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "model._infer_aspect_weight() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.aspect_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40823205,  0.4831515 , -0.17405096, -0.47696896,  0.09275198,\n",
       "        0.79349162])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.delta_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.m_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2253214476301908"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.821404045634148"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.delta_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
