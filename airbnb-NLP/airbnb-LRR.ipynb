{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chankoo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "K = 6\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [5,5,4,3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    W['w_'+str(k)] = np.random.randint(0,high = 5,size=(D,N) ,dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = np.zeros((D,K,N),dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    for d in range(D): \n",
    "        W2[d][k] = W['w_'+str(k)][d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.70752466,  0.03806972,  0.02335534, -0.07184985, -0.21061131,\n",
       "       -0.31549415], dtype=float32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_0 = np.array(np.random.rand(K) * 2.0 - np.ones((K)),dtype='float32')\n",
    "mu_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_0 = np.array(np.identity(K,dtype='float32'))\n",
    "sigma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24938298,  0.88092023,  0.96387932,  1.19321081, -0.1043185 ,\n",
       "         1.03167607],\n",
       "       [-1.36069066,  1.27536926,  0.25290939,  0.51437761, -0.013455  ,\n",
       "        -0.91282985],\n",
       "       [-0.95626935, -0.10907779, -0.26746498,  1.16686273, -0.99313553,\n",
       "         0.2258339 ],\n",
       "       [ 2.29420473, -1.32935291, -0.41357428,  1.27115083,  0.6426769 ,\n",
       "         0.54380792],\n",
       "       [-0.44568435, -0.39624808, -0.71660223,  1.67179923, -1.01756768,\n",
       "        -0.7561521 ]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_hat_0 = np.random.normal(loc = mu_0, scale= sigma_0.diagonal(),size = (D,K) )\n",
    "alpha_hat_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0144656 , 0.04479412, 0.0486687 , 0.06121348, 0.01672389,\n",
       "        0.0520827 ],\n",
       "       [0.00476104, 0.06645506, 0.02390448, 0.031048  , 0.01831466,\n",
       "        0.00745084],\n",
       "       [0.00713411, 0.01664448, 0.01420639, 0.05962169, 0.00687589,\n",
       "        0.02326594],\n",
       "       [0.18407834, 0.0049126 , 0.01227522, 0.06617532, 0.03529826,\n",
       "        0.03197533],\n",
       "       [0.01188732, 0.01248975, 0.00906621, 0.098786  , 0.00670993,\n",
       "        0.00871464]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_0 = np.exp(alpha_hat_0)/np.sum(np.exp(alpha_hat_0))\n",
    "alpha_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02548366,  0.08036695, -0.08206261,  0.08121232,  0.06949994,\n",
       "         0.09651957, -0.05386621,  0.00248668,  0.05271601, -0.00615398],\n",
       "       [-0.00534419,  0.07079478, -0.06157328,  0.0640165 , -0.05443381,\n",
       "         0.01562076, -0.02882842, -0.09236123,  0.03597522, -0.05940575],\n",
       "       [-0.03133282, -0.0516488 , -0.06427151,  0.03898093, -0.02691578,\n",
       "        -0.0241933 , -0.08954012, -0.08698585,  0.02425431,  0.06478388],\n",
       "       [ 0.00623898, -0.05383178, -0.08017184, -0.02157001,  0.06635117,\n",
       "        -0.08926516, -0.03293576,  0.08168465,  0.09177446,  0.09616955],\n",
       "       [-0.09591533,  0.02302901,  0.08371054,  0.07855335, -0.01681843,\n",
       "         0.06564218, -0.05953276,  0.06019444, -0.0639237 , -0.04285208],\n",
       "       [-0.05071892,  0.0355148 , -0.07885524, -0.02176891, -0.03722655,\n",
       "         0.06862206,  0.09413073,  0.01144626,  0.04068504,  0.01559115]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86911262, 2.51133475, 0.79262366, 0.83292179, 1.3835091 ,\n",
       "        1.72245512],\n",
       "       [1.56970731, 1.28077938, 0.53736761, 1.05700677, 1.67815938,\n",
       "        1.12308689],\n",
       "       [0.85739531, 2.42023864, 0.69253216, 1.61605403, 1.38279465,\n",
       "        1.37056831],\n",
       "       [1.72155581, 3.5254284 , 0.53955592, 1.33774667, 1.32116659,\n",
       "        1.49361631],\n",
       "       [1.23771014, 2.17791606, 0.80838737, 1.46112601, 1.41067701,\n",
       "        1.03103525]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_0 =  model.aspect_rating_T[0]\n",
    "S_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [5, 5, 4, 3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_0 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_inv_0 = np.linalg.inv(np.identity(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[-0.25938296  0.87092024  0.95387936  1.1832108  -0.1143185   1.0216761 ]\n",
      " [-1.3706907   1.2653693   0.24290939  0.5043776  -0.023455   -0.92282987]\n",
      " [-0.9662693  -0.11907779 -0.277465    1.1568627  -1.0031356   0.2158339 ]\n",
      " [ 2.2842047  -1.3393528  -0.42357427  1.2611508   0.6326769   0.53380793]\n",
      " [-0.45568433 -0.40624806 -0.7266022   1.6617992  -1.0275676  -0.7661521 ]]\n",
      "20 [[-0.45938277  0.67092043  0.75387955  0.98321104 -0.3143185   0.82167625]\n",
      " [-1.5706905   1.0653695   0.04290935  0.3043778  -0.22345503 -1.1228297 ]\n",
      " [-1.1662692  -0.3190778  -0.4774648   0.9568629  -1.2031354   0.01583387]\n",
      " [ 2.084205   -1.5393527  -0.6235741   1.061151    0.4326771   0.33380812]\n",
      " [-0.6556842  -0.6062479  -0.926602    1.4617994  -1.2275674  -0.9661519 ]]\n",
      "40 [[-0.6593826   0.47092062  0.55387974  0.78321123 -0.51431835  0.62167645]\n",
      " [-1.7706903   0.8653697  -0.15709065  0.10437778 -0.42345488 -1.3228295 ]\n",
      " [-1.366269   -0.5190776  -0.6774646   0.7568631  -1.4031352  -0.18416613]\n",
      " [ 1.8842051  -1.7393525  -0.8235739   0.8611512   0.23267725  0.13380814]\n",
      " [-0.855684   -0.8062477  -1.1266018   1.2617996  -1.4275672  -1.1661518 ]]\n",
      "60 [[-0.8593824   0.2709208   0.35387993  0.5832114  -0.71431816  0.42167664]\n",
      " [-1.9706901   0.66536987 -0.3570906  -0.09562219 -0.6234547  -1.5228293 ]\n",
      " [-1.5662688  -0.7190774  -0.8774644   0.5568633  -1.603135   -0.38416603]\n",
      " [ 1.6842053  -1.9393523  -1.0235738   0.6611514   0.03267722 -0.06619184]\n",
      " [-1.0556839  -1.0062475  -1.3266016   1.0617998  -1.627567   -1.3661516 ]]\n",
      "80 [[-1.0593822   0.07092078  0.15387997  0.3832116  -0.91431797  0.22167678]\n",
      " [-2.17069     0.46537006 -0.5570904  -0.2956222  -0.8234545  -1.7228291 ]\n",
      " [-1.7662686  -0.9190772  -1.0774642   0.3568635  -1.8031348  -0.5841659 ]\n",
      " [ 1.4842055  -2.139352   -1.2235736   0.4611516  -0.16732278 -0.26619187]\n",
      " [-1.2556837  -1.2062473  -1.5266014   0.86179996 -1.8275669  -1.5661514 ]]\n",
      "100 [[-1.259382   -0.1290792  -0.04612002  0.1832117  -1.1143178   0.02167675]\n",
      " [-2.3706899   0.26537025 -0.7570902  -0.495622   -1.0234543  -1.9228289 ]\n",
      " [-1.9662684  -1.1190771  -1.277464    0.15686354 -2.0031347  -0.7841657 ]\n",
      " [ 1.2842057  -2.339352   -1.4235734   0.2611518  -0.3673227  -0.46619168]\n",
      " [-1.4556835  -1.4062471  -1.7266012   0.66180015 -2.0275667  -1.7661512 ]]\n",
      "120 [[-1.4593818  -0.32907918 -0.24612007 -0.01678831 -1.3143176  -0.17832325]\n",
      " [-2.5706897   0.0653702  -0.95709    -0.69562185 -1.2234541  -2.1228287 ]\n",
      " [-2.1662683  -1.3190769  -1.4774638  -0.04313646 -2.2031345  -0.9841655 ]\n",
      " [ 1.0842059  -2.5393517  -1.6235732   0.06115175 -0.56732255 -0.6661915 ]\n",
      " [-1.6556833  -1.606247   -1.926601    0.46180034 -2.2275665  -1.966151  ]]\n",
      "140 [[-1.6593816  -0.529079   -0.44611987 -0.21678834 -1.5143174  -0.37832317]\n",
      " [-2.7706895  -0.13462977 -1.1570898  -0.89562166 -1.4234539  -2.3228285 ]\n",
      " [-2.3662682  -1.5190767  -1.6774637  -0.2431365  -2.4031343  -1.1841654 ]\n",
      " [ 0.88420606 -2.7393515  -1.823573   -0.13884823 -0.76732236 -0.8661913 ]\n",
      " [-1.8556831  -1.8062468  -2.126601    0.26180053 -2.4275663  -2.1661508 ]]\n",
      "160 [[-1.8593814  -0.7290788  -0.6461197  -0.4167882  -1.7143172  -0.578323  ]\n",
      " [-2.9706893  -0.33462974 -1.3570896  -1.0956215  -1.6234537  -2.5228283 ]\n",
      " [-2.566268   -1.7190765  -1.8774635  -0.4431363  -2.6031342  -1.3841652 ]\n",
      " [ 0.68420625 -2.9393513  -2.023573   -0.3388482  -0.9673222  -1.0661912 ]\n",
      " [-2.055683   -2.0062466  -2.3266008   0.06180049 -2.627566   -2.3661506 ]]\n",
      "180 [[-2.0593812  -0.92907864 -0.8461195  -0.616788   -1.914317   -0.7783228 ]\n",
      " [-3.170689   -0.5346296  -1.5570894  -1.2956213  -1.8234535  -2.7228281 ]\n",
      " [-2.7662678  -1.9190763  -2.0774634  -0.64313614 -2.803134   -1.584165  ]\n",
      " [ 0.48420644 -3.1393511  -2.2235727  -0.53884804 -1.167322   -1.266191  ]\n",
      " [-2.2556827  -2.2062464  -2.5266006  -0.1381995  -2.827566   -2.5661504 ]]\n",
      "200 [[-2.259381   -1.1290785  -1.0461193  -0.81678784 -2.114317   -0.9783226 ]\n",
      " [-3.370689   -0.7346294  -1.7570893  -1.4956211  -2.0234535  -2.922828  ]\n",
      " [-2.9662676  -2.1190763  -2.2774632  -0.84313595 -3.0031338  -1.7841648 ]\n",
      " [ 0.28420663 -3.339351   -2.4235725  -0.73884785 -1.3673218  -1.4661908 ]\n",
      " [-2.4556825  -2.4062462  -2.7266004  -0.33819947 -3.0275657  -2.7661502 ]]\n"
     ]
    }
   ],
   "source": [
    "mu_data = mu_0\n",
    "sigma_data = sigma_0\n",
    "sigma_inv_data = np.linalg.inv(sigma_0)\n",
    "delta_data = delta_0\n",
    "s_data = S_0\n",
    "\n",
    "rating_data = [5,5,4,3,0]\n",
    " \n",
    "alpha_hat_data = alpha_hat_0\n",
    "\n",
    "alpha_hat = tf.Variable(alpha_hat_0, name = 'aspect_weight_hat',dtype=tf.float32)\n",
    "# mu = tf.placeholder(tf.float32,shape=(K),name='mu')\n",
    "# sigma_inv = tf.placeholder(tf.float32,shape=(K,K),name='sigma_inv')\n",
    "# delta = tf.placeholder(tf.float32,name='delta')\n",
    "# s = tf.placeholder(tf.float32,shape=(D,K),name = 'aspect_rating')\n",
    "# preceding = tf.placeholder(tf.float32,shape=(D,K),name='precending')\n",
    "\n",
    "mu = tf.placeholder_with_default(mu_data,shape=(K),name='mu')\n",
    "sigma_inv = tf.placeholder_with_default(sigma_inv_data,shape=(K,K),name='sigma_inv')\n",
    "delta = tf.placeholder_with_default(delta_data,shape=None,name='delta')\n",
    "s = tf.placeholder_with_default(s_data,shape=(D,K),name = 'aspect_rating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rating = tf.placeholder(tf.int16,shape=(D))\n",
    " \n",
    "    \n",
    "preceding_data = np.zeros((D,K),dtype='float32')\n",
    "for d in range(D):\n",
    "    preceding_data[d] = (((rating_data - np.matmul(alpha_hat_data,s_data.T).diagonal())[d]*s_data[d]) )\n",
    "\n",
    "preceding = tf.placeholder_with_default(preceding_data,shape=(D,K),name='precending')\n",
    "loss =  preceding/tf.square(delta) + tf.matmul((alpha_hat-mu),sigma_inv)\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(201):\n",
    "#         sess.run([alpha_hat,train] # feed_dict 넣으면 에러 왜지\n",
    "#                  , feed_dict={preceding: preceding_data,delta:delta_data,alpha_hat:alpha_hat_data,sigma_inv:sigma_inv_data,mu:mu_data})\n",
    "        res = sess.run([alpha_hat,train])\n",
    "        if step % 20 == 0:\n",
    "            print(step, sess.run(alpha_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRR_Model:\n",
    "    global W2\n",
    "    W = W2\n",
    "    SCORE_SQUARE = False\n",
    "    \n",
    "    K = None # num of aspects\n",
    "    D = None # num of documents\n",
    "    N = None # num of words\n",
    "    \n",
    "    T = 1000 # max iteration\n",
    "    \n",
    "    mu_T = [0 for _ in range(T)]\n",
    "    sigma_T = [0 for _ in range(T)]\n",
    "    sigma_inv_T = [0 for _ in range(T)]\n",
    "    delta_T = [0 for _ in range(T)]\n",
    "    beta_T = [0 for _ in range(T)]\n",
    "    \n",
    "    aspect_weight_T = [0 for _ in range(T)] # alpha\n",
    "    alpha_hat_T = [0 for _ in range(T)]\n",
    "    \n",
    "    aspect_rating_T = [0 for _ in range(T)] # S\n",
    "    \n",
    "    ratings = None\n",
    "    \n",
    "    def __init__(self,k,d,n,ratings:list):\n",
    "        self.K = k\n",
    "        self.D = d\n",
    "        self.N = n\n",
    "        self.ratings = np.array(ratings,dtype='int16')\n",
    "        \n",
    "        self.mu_T[0] = np.array(np.random.rand(self.K) * 2.0 - np.ones(self.K) ,dtype='float32')\n",
    "        self.sigma_T[0] = np.array(np.identity(self.K),dtype='float32')\n",
    "        self.sigma_inv_T[0] = np.linalg.inv(self.sigma_T[0])\n",
    "        \n",
    "        self.beta_T[0] = (2*np.random.rand(self.K, self.N)-1.0)/10\n",
    "        self.delta_T[0] = 1.0\n",
    "        \n",
    "        self.alpha_hat_T[0] = np.random.normal(loc = self.mu_T[0], scale= self.sigma_T[0].diagonal(),size=(D,K) )\n",
    "        self.aspect_weight_T[0] = np.exp(self.alpha_hat_T[0])/np.sum(np.exp(self.alpha_hat_T[0]))\n",
    "        \n",
    "    \n",
    "#     def calc_covariance(self,vct):\n",
    "#         '''\n",
    "#         :param vct:\n",
    "#         :return:\n",
    "\n",
    "#         double sum = 0, s;\n",
    "# \t\tfor(int i=0; i<m_k; i++){\n",
    "# \t\t\ts = 0;\n",
    "# \t\t\tfor(int j=0; j<m_k; j++)\n",
    "# \t\t\t\ts += vct[j] * m_sigma_inv[j][i];\n",
    "# \t\t\tsum += s * vct[i];\n",
    "# \t\t}\n",
    "# \t\treturn sum;\n",
    "\n",
    "#         '''\n",
    "\n",
    "#     def calc_det(self):\n",
    "#         return np.linalg.det(self.sigma)\n",
    "\n",
    "#     def calc_sigma_inv(self,scale):\n",
    "#         self.sigma_inv = np.linalg.inv(self.sigma) * scale\n",
    "\n",
    "    def save(self,file_name:str):\n",
    "        print(os.path.join(os.getcwd(), os.path.join('model', file_name)))\n",
    "        with open(os.path.join(os.getcwd(), os.path.join('model', file_name)), 'wb') as fp:\n",
    "            pickle.dump(self,fp)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls,file_name:str):\n",
    "        try:\n",
    "            with open(os.path.join(os.getcwd(),os.path.join('model',file_name)),'rb') as fp:\n",
    "                return pickle.load(fp)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def fill_aspect_rating(self,t):\n",
    "        aspect_rating = np.zeros((D,K))\n",
    "        if self.SCORE_SQUARE==True:\n",
    "            for d in range(D):\n",
    "                aspect_rating[d] = 0.5*np.sum(np.multiply(self.beta_T[t],self.W[d]),axis=1)#to avoid negative rating \n",
    "            self.aspect_rating_T[t] = aspect_rating\n",
    "        else:\n",
    "            for d in range(D):\n",
    "                aspect_rating[d] = np.exp(np.sum(np.multiply(self.beta_T[t],self.W[d]),axis=1))#to avoid negative rating \n",
    "            self.aspect_rating_T[t] = aspect_rating\n",
    "            \n",
    "    def infer_aspect_weight(self):\n",
    "\n",
    "        alpha_hat = tf.Variable(self.alpha_hat_T[0], name = 'aspect_weight_hat',dtype=tf.float32)\n",
    "\n",
    "        mu = tf.placeholder_with_default(self.mu_T[0],shape=(K),name='mu')\n",
    "        sigma_inv = tf.placeholder_with_default(self.sigma_inv_T[0],shape=(K,K),name='sigma_inv')\n",
    "        delta = tf.placeholder_with_default(self.delta_T[0],shape=None,name='delta')\n",
    "        s = tf.placeholder_with_default(self.aspect_rating_T[0],shape=(D,K),name = 'aspect_rating')\n",
    "        ratings = tf.placeholder_with_default(self.ratings,shape=(D),name = 'ratings')\n",
    "\n",
    "#         preceding_tmp = np.zeros((D,K),dtype='float32')\n",
    "#         for d in range(D):\n",
    "#             preceding_tmp[d] = (((self.ratings - np.matmul(self.alpha_hat_T[0],self.aspect_rating_T[0].T).diagonal())[d]*self.aspect_rating_T[0][d]) )\n",
    "\n",
    "#         preceding = tf.placeholder_with_default(preceding_tmp,shape=(D,K),name='precending')\n",
    "        \n",
    "        loss = tf.square( ratings - tf.matmul(alpha_hat,tf.transpose(s)).diagonal() )#/(2*tf.square(delta)) + 0.5*tf.matmul(tf.matmul(tf.transpose(tf.subtract(alpha_hat,mu)), sigma_inv),tf.subtract(alpha_hat,mu))\n",
    "\n",
    "#         grad =  preceding/tf.square(delta) + tf.matmul((alpha_hat-mu),sigma_inv)\n",
    "\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "        train = optimizer.minimize(loss)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for step in range(20001):\n",
    "                res = sess.run([alpha_hat,train])\n",
    "                if step % 2000 == 0:\n",
    "                    print(step,':')\n",
    "                    print(sess.run(loss),'\\n') \n",
    "                    print(sess.run(alpha_hat),'\\n')\n",
    "        res[0]\n",
    "\n",
    "    \n",
    "    def e_step():\n",
    "        #infer_aspect_weight()\n",
    "        pass\n",
    "    def m_step():\n",
    "        pass\n",
    "    \n",
    "    def em_est(converge:float):\n",
    "#         e_step()\n",
    "#         m_step()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LRR_Model(6,5,10,ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chankoo\\Desktop\\GitHub\\BOAZ-projects\\airbnb-NLP\\model\\test.model\n"
     ]
    }
   ],
   "source": [
    "model.save('test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LRR_Model.load('test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fill_aspect_rating(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.43954313, 0.5978312 , 0.73965258, 1.26437988, 1.85234575,\n",
       "        0.74381179],\n",
       "       [1.68276628, 1.40364058, 0.98662563, 2.27363046, 1.96375773,\n",
       "        0.82424799],\n",
       "       [1.43760533, 1.23470944, 0.98675005, 2.88506463, 1.11469147,\n",
       "        0.72933687],\n",
       "       [1.45638509, 0.89960231, 1.41219239, 0.86332215, 1.92997509,\n",
       "        0.95200432],\n",
       "       [1.28145809, 0.69602701, 1.12522457, 1.28784087, 1.73820357,\n",
       "        0.64141784]])"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.aspect_rating_T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.infer_aspect_weight() # 수렴안하는 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
