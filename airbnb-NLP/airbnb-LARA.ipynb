{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chankoo\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Chankoo\\\\Desktop\\\\GitHub\\\\BOAZ-projects\\\\airbnb-NLP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./../airbnb-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos_review.json') as fp:\n",
    "    review = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30569"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_lst = list(review.keys())\n",
    "sampled_key_lst = key_lst[:100]\n",
    "review2 = {}\n",
    "for k in sampled_key_lst:\n",
    "    review2[k] = review[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('voca_freq_dic.json') as fp:\n",
    "    voca_freq_dic = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223731"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voca_freq_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_freq_dic2 = {}\n",
    "for k,v in voca_freq_dic.items():\n",
    "    if v>9:\n",
    "        voca_freq_dic2[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22384"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voca_freq_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('windowsthe_N', 10),\n",
       " ('bythe_N', 10),\n",
       " ('hairbrush_N', 10),\n",
       " ('convenientim_N', 10),\n",
       " ('score_R', 10),\n",
       " ('pouch_J', 10),\n",
       " ('paternal_J', 10),\n",
       " ('test_R', 10),\n",
       " ('equipped_N', 10),\n",
       " ('greateverything_V', 10),\n",
       " ('sophie_V', 10),\n",
       " ('officially_R', 10),\n",
       " ('nicest_R', 10),\n",
       " ('fed_N', 10),\n",
       " ('voluntary_J', 10),\n",
       " ('character_V', 10),\n",
       " ('goodness_J', 10),\n",
       " ('savvy_N', 10),\n",
       " ('pricewe_N', 10),\n",
       " ('midterm_N', 10),\n",
       " ('coexist_V', 10),\n",
       " ('wellwe_N', 10),\n",
       " ('woukd_N', 10),\n",
       " ('presented_J', 10),\n",
       " ('wasi_N', 10),\n",
       " ('enclosure_N', 10),\n",
       " ('except_N', 10),\n",
       " ('tense_J', 10),\n",
       " ('moviethe_N', 10),\n",
       " ('poi_N', 10),\n",
       " ('gifti_N', 10),\n",
       " ('taiwan_R', 10),\n",
       " ('carsit_N', 10),\n",
       " ('placeabove_N', 10),\n",
       " ('watered_J', 10),\n",
       " ('fall_R', 10),\n",
       " ('cleanjust_N', 10),\n",
       " ('positioning_N', 10),\n",
       " ('eyeglass_N', 10),\n",
       " ('rust_N', 10),\n",
       " ('sidei_N', 10),\n",
       " ('comfortablehowever_N', 10),\n",
       " ('wellknown_N', 10),\n",
       " ('enterance_N', 10),\n",
       " ('awful_N', 10),\n",
       " ('theme_J', 10),\n",
       " ('terror_N', 10),\n",
       " ('descent_J', 10),\n",
       " ('buildingi_V', 10),\n",
       " ('smoke_J', 10),\n",
       " ('travelling_J', 10),\n",
       " ('sedan_N', 10),\n",
       " ('keonhees_N', 10),\n",
       " ('owneri_N', 10),\n",
       " ('info_R', 10),\n",
       " ('closeness_J', 10),\n",
       " ('thoughtyour_N', 10),\n",
       " ('greatill_N', 10),\n",
       " ('accommodating_J', 10),\n",
       " ('helpand_N', 10),\n",
       " ('satisfactoryhaha_N', 10),\n",
       " ('endthe_J', 10),\n",
       " ('discomforti_N', 10),\n",
       " ('deeply_V', 10),\n",
       " ('citythank_N', 10),\n",
       " ('chris_R', 10),\n",
       " ('wellplaced_J', 10),\n",
       " ('korail_V', 10),\n",
       " ('responseits_N', 10),\n",
       " ('plce_N', 10),\n",
       " ('bu_N', 10),\n",
       " ('opp_N', 10),\n",
       " ('openhearted_V', 10),\n",
       " ('purification_N', 10),\n",
       " ('af_N', 10),\n",
       " ('stronger_N', 10),\n",
       " ('busanits_N', 10),\n",
       " ('goodabove_V', 10),\n",
       " ('obsess_V', 10),\n",
       " ('greatgreat_N', 10),\n",
       " ('plane_J', 10),\n",
       " ('suntan_N', 10),\n",
       " ('roomnice_N', 10),\n",
       " ('selfchecking_N', 10),\n",
       " ('outyou_J', 10),\n",
       " ('lanterns_V', 10),\n",
       " ('awesomethe_N', 10),\n",
       " ('usthere_R', 10),\n",
       " ('biscuits_V', 10),\n",
       " ('stephen_N', 10),\n",
       " ('shoofer_N', 10),\n",
       " ('greatit_R', 10),\n",
       " ('hide_J', 10),\n",
       " ('mipo_J', 10),\n",
       " ('gangwon_J', 10),\n",
       " ('delicioushaha_N', 10),\n",
       " ('thumbsup_N', 10),\n",
       " ('roomsince_N', 10),\n",
       " ('subtitle_N', 10),\n",
       " ('kindnessthe_J', 10),\n",
       " ('backit_N', 10),\n",
       " ('bar_R', 10),\n",
       " ('pho_N', 10),\n",
       " ('differentiate_V', 10),\n",
       " ('tripwhen_N', 10),\n",
       " ('snap_J', 10),\n",
       " ('revise_V', 10),\n",
       " ('expectedthank_N', 10),\n",
       " ('transportationif_N', 10),\n",
       " ('india_J', 10),\n",
       " ('bluetooth_R', 10),\n",
       " ('travelingi_N', 10),\n",
       " ('stationit_R', 10),\n",
       " ('tie_R', 10),\n",
       " ('noisei_N', 10),\n",
       " ('happily_N', 10),\n",
       " ('pat_N', 10),\n",
       " ('nightas_N', 10),\n",
       " ('boiling_J', 10),\n",
       " ('posti_N', 10),\n",
       " ('dove_N', 10),\n",
       " ('wound_N', 10),\n",
       " ('plumber_N', 10),\n",
       " ('awayhowever_R', 10),\n",
       " ('yejis_N', 10),\n",
       " ('prospect_V', 10),\n",
       " ('latter_V', 10),\n",
       " ('pu_N', 10),\n",
       " ('jiaes_N', 10),\n",
       " ('embalm_V', 10),\n",
       " ('walkif_N', 10),\n",
       " ('equippedit_R', 10),\n",
       " ('communicateits_N', 10),\n",
       " ('flop_N', 10),\n",
       " ('againbut_N', 10),\n",
       " ('turtle_N', 10),\n",
       " ('responser_N', 10),\n",
       " ('heatingthe_N', 10),\n",
       " ('roadbut_N', 10),\n",
       " ('bulgogi_J', 10),\n",
       " ('bestill_N', 10),\n",
       " ('comfortablealthough_N', 10),\n",
       " ('kingsized_V', 10),\n",
       " ('dishesthe_J', 10),\n",
       " ('windowand_N', 10),\n",
       " ('etcthe_R', 10),\n",
       " ('diversion_N', 10),\n",
       " ('wellwatered_V', 10),\n",
       " ('bedclothesi_N', 10),\n",
       " ('seokguram_J', 10),\n",
       " ('juan_N', 10),\n",
       " ('adultsi_N', 10),\n",
       " ('espresso_V', 10),\n",
       " ('fantasticthe_N', 10),\n",
       " ('psychological_J', 10),\n",
       " ('themthere_R', 10),\n",
       " ('kit_J', 10),\n",
       " ('confusing_N', 10),\n",
       " ('wasit_N', 10),\n",
       " ('sleepand_N', 10),\n",
       " ('eungeun_N', 10),\n",
       " ('proxy_J', 10),\n",
       " ('cleanthank_V', 10),\n",
       " ('restuarant_J', 10),\n",
       " ('sweater_N', 10),\n",
       " ('destination_J', 10),\n",
       " ('placetheres_N', 10),\n",
       " ('travelersthe_N', 10),\n",
       " ('tres_N', 10),\n",
       " ('situ_N', 10),\n",
       " ('asian_N', 10),\n",
       " ('standby_J', 10),\n",
       " ('jiffy_N', 10),\n",
       " ('stationalthough_J', 10),\n",
       " ('adventure_J', 10),\n",
       " ('viewhowever_N', 10),\n",
       " ('darkness_J', 10),\n",
       " ('safelyi_J', 10),\n",
       " ('loli_N', 10),\n",
       " ('elbe_V', 10),\n",
       " ('prettyespecially_R', 10),\n",
       " ('busani_R', 10),\n",
       " ('mapit_N', 10),\n",
       " ('mallit_N', 10),\n",
       " ('el_V', 10),\n",
       " ('shinsagae_N', 10),\n",
       " ('positionedthe_J', 10),\n",
       " ('inconvenienced_J', 10),\n",
       " ('patbingsu_N', 10),\n",
       " ('couch_R', 10),\n",
       " ('unsatisfactory_N', 10),\n",
       " ('visiti_J', 10),\n",
       " ('wrong_N', 10),\n",
       " ('namely_R', 10),\n",
       " ('blog_V', 10),\n",
       " ('labor_N', 10),\n",
       " ('sorryi_N', 10),\n",
       " ('littlethe_J', 10),\n",
       " ('q_V', 10),\n",
       " ('minute_R', 10),\n",
       " ('kitchenand_N', 10),\n",
       " ('wiling_V', 10),\n",
       " ('thru_R', 10),\n",
       " ('islandi_V', 10),\n",
       " ('foodie_V', 10),\n",
       " ('seashore_V', 10),\n",
       " ('gap_J', 10),\n",
       " ('placenear_N', 10),\n",
       " ('holidayi_N', 10),\n",
       " ('hosthaha_N', 10),\n",
       " ('nov_R', 10),\n",
       " ('welleverything_V', 10),\n",
       " ('olivia_V', 10),\n",
       " ('appart_R', 10),\n",
       " ('wellcom_V', 10),\n",
       " ('airbnbiro_N', 10),\n",
       " ('awayhaha_N', 10),\n",
       " ('perfectim_N', 10),\n",
       " ('foyer_N', 10),\n",
       " ('sleepingthe_N', 10),\n",
       " ('awake_R', 10),\n",
       " ('nighthaha_N', 10),\n",
       " ('taxii_N', 10),\n",
       " ('girlfriendi_N', 10),\n",
       " ('recommendedits_N', 10),\n",
       " ('kindnext_N', 10),\n",
       " ('verandai_N', 10),\n",
       " ('draught_V', 10),\n",
       " ('temples_V', 10),\n",
       " ('siteseeing_V', 10),\n",
       " ('staple_N', 10),\n",
       " ('drinks_J', 10),\n",
       " ('patientthe_N', 10),\n",
       " ('unpack_R', 10),\n",
       " ('daytoday_J', 10),\n",
       " ('serve_J', 10),\n",
       " ('somis_N', 10),\n",
       " ('highrise_J', 10),\n",
       " ('aroundif_N', 10),\n",
       " ('lyle_N', 10),\n",
       " ('bedsthe_J', 10),\n",
       " ('softthe_N', 10),\n",
       " ('muchhaha_N', 10),\n",
       " ('violet_N', 10),\n",
       " ('fineit_J', 10),\n",
       " ('togetherit_J', 10),\n",
       " ('notify_N', 10),\n",
       " ('streetand_N', 10),\n",
       " ('dan_J', 10),\n",
       " ('ver_R', 10),\n",
       " ('drivethe_N', 10),\n",
       " ('definitelly_R', 10),\n",
       " ('circus_N', 10),\n",
       " ('fav_N', 10),\n",
       " ('ark_N', 10),\n",
       " ('relaxhaha_N', 10),\n",
       " ('plateau_N', 10),\n",
       " ('coldand_N', 10),\n",
       " ('stationary_J', 10),\n",
       " ('atopic_N', 10),\n",
       " ('comfortablythanks_N', 10),\n",
       " ('farthest_J', 10),\n",
       " ('earplug_J', 10),\n",
       " ('respondthe_N', 10),\n",
       " ('bigthe_J', 10),\n",
       " ('caramel_N', 10),\n",
       " ('tastei_N', 10),\n",
       " ('sajik_N', 10),\n",
       " ('heartedly_R', 10),\n",
       " ('jamess_J', 10),\n",
       " ('temper_N', 10),\n",
       " ('erratic_J', 10),\n",
       " ('supportive_V', 10),\n",
       " ('restroom_J', 10),\n",
       " ('luggagethere_R', 10),\n",
       " ('cozyand_N', 10),\n",
       " ('centrality_N', 10),\n",
       " ('impersonal_J', 10),\n",
       " ('cookit_N', 10),\n",
       " ('inbox_N', 10),\n",
       " ('timed_N', 10),\n",
       " ('homethere_J', 10),\n",
       " ('bhc_V', 10),\n",
       " ('ahn_N', 10),\n",
       " ('sihoos_J', 10),\n",
       " ('palatable_J', 10),\n",
       " ('descriptionthe_N', 10),\n",
       " ('walkin_J', 10),\n",
       " ('superficial_J', 10),\n",
       " ('thoughtfulits_N', 10),\n",
       " ('bar_J', 10),\n",
       " ('stationmins_N', 10),\n",
       " ('piss_V', 10),\n",
       " ('prefer_R', 10),\n",
       " ('leftit_N', 10),\n",
       " ('considerately_R', 10),\n",
       " ('surly_R', 10),\n",
       " ('unpredictable_J', 10),\n",
       " ('furnishedthe_J', 10),\n",
       " ('modernise_V', 10),\n",
       " ('stayespecially_R', 10),\n",
       " ('questionsit_N', 10),\n",
       " ('volunteered_J', 10),\n",
       " ('restas_N', 10),\n",
       " ('walkit_V', 10),\n",
       " ('replacement_J', 10),\n",
       " ('soundproof_R', 10),\n",
       " ('shoppingrestaurants_N', 10),\n",
       " ('itafter_N', 10),\n",
       " ('topokki_N', 10),\n",
       " ('problemthere_R', 10),\n",
       " ('palate_N', 10),\n",
       " ('actuality_N', 10),\n",
       " ('nearbythere_J', 10),\n",
       " ('advertise_N', 10),\n",
       " ('pharmacist_N', 10),\n",
       " ('object_V', 10),\n",
       " ('well_J', 10),\n",
       " ('presentable_J', 10),\n",
       " ('haru_R', 10),\n",
       " ('washlet_N', 10),\n",
       " ('hyodo_N', 10),\n",
       " ('onthe_R', 10),\n",
       " ('advisor_N', 10),\n",
       " ('hypermart_N', 10),\n",
       " ('dealer_N', 10),\n",
       " ('washed_N', 10),\n",
       " ('glue_N', 10),\n",
       " ('thingthe_J', 10),\n",
       " ('closeand_N', 10),\n",
       " ('immediatelythe_N', 10),\n",
       " ('convenientlylocated_V', 10),\n",
       " ('jamie_J', 10),\n",
       " ('hotellevel_N', 10),\n",
       " ('thoughtthanks_N', 10),\n",
       " ('interiorit_J', 10),\n",
       " ('phonei_N', 10),\n",
       " ('warmlyi_N', 10),\n",
       " ('airthe_N', 10),\n",
       " ('late_N', 10),\n",
       " ('lugagges_N', 10),\n",
       " ('drum_J', 10),\n",
       " ('machineits_N', 10),\n",
       " ('shopa_N', 10),\n",
       " ('nicebest_J', 10),\n",
       " ('elf_N', 10),\n",
       " ('replay_N', 10),\n",
       " ('warmthere_J', 10),\n",
       " ('og_J', 10),\n",
       " ('standby_N', 10),\n",
       " ('overflow_N', 10),\n",
       " ('frequency_N', 10),\n",
       " ('seascape_N', 10),\n",
       " ('seomyun_R', 10),\n",
       " ('wax_N', 10),\n",
       " ('buan_N', 10),\n",
       " ('bigbut_N', 10),\n",
       " ('bum_V', 10),\n",
       " ('visiting_J', 10),\n",
       " ('phew_N', 10),\n",
       " ('positioni_N', 10),\n",
       " ('itand_J', 10),\n",
       " ('guise_N', 10),\n",
       " ('seatheres_N', 10),\n",
       " ('missingi_N', 10),\n",
       " ('thoughtwhen_N', 10),\n",
       " ('informational_J', 10),\n",
       " ('quest_N', 10),\n",
       " ('donghae_V', 10),\n",
       " ('lg_J', 10),\n",
       " ('terrier_R', 10),\n",
       " ('tofrom_V', 10),\n",
       " ('lb_N', 10),\n",
       " ('dayyou_N', 10),\n",
       " ('linethe_J', 10),\n",
       " ('insist_J', 10),\n",
       " ('careits_N', 10),\n",
       " ('heregood_N', 10),\n",
       " ('starve_N', 10),\n",
       " ('bloody_N', 10),\n",
       " ('accommodative_V', 10),\n",
       " ('wellill_N', 10),\n",
       " ('duvet_V', 10),\n",
       " ('readythe_J', 10),\n",
       " ('gangster_N', 10),\n",
       " ('itmy_N', 10),\n",
       " ('epic_J', 10),\n",
       " ('charging_N', 10),\n",
       " ('message_R', 10),\n",
       " ('disappoints_N', 10),\n",
       " ('mcdonald_J', 10),\n",
       " ('friendlythank_N', 10),\n",
       " ('styler_N', 10),\n",
       " ('midnight_R', 10),\n",
       " ('greathowever_N', 10),\n",
       " ('locationtheres_N', 10),\n",
       " ('homewhen_N', 10),\n",
       " ('storing_N', 10),\n",
       " ('mosquitos_J', 10),\n",
       " ('discrepancy_N', 10),\n",
       " ('hop_J', 10),\n",
       " ('costit_N', 10),\n",
       " ('areai_J', 10),\n",
       " ('flushing_N', 10),\n",
       " ('beau_V', 10),\n",
       " ('birch_N', 10),\n",
       " ('rag_V', 10),\n",
       " ('outsideit_R', 10),\n",
       " ('carethe_N', 10),\n",
       " ('kang_J', 10),\n",
       " ('oneperson_N', 10),\n",
       " ('cart_V', 10),\n",
       " ('damn_R', 10),\n",
       " ('nightclub_J', 10),\n",
       " ('chitchat_N', 10),\n",
       " ('housefirst_J', 10),\n",
       " ('nicest_N', 10),\n",
       " ('playground_R', 10),\n",
       " ('myselfthank_N', 10),\n",
       " ('hangul_V', 10),\n",
       " ('mimis_J', 10),\n",
       " ('symptom_N', 10),\n",
       " ('label_J', 10),\n",
       " ('dogthe_N', 10),\n",
       " ('monthold_R', 10),\n",
       " ('eunjin_R', 10),\n",
       " ('chomseongdae_N', 10),\n",
       " ('nearit_N', 10),\n",
       " ('fullsized_V', 10),\n",
       " ('pricei_J', 10),\n",
       " ('rearrange_N', 10),\n",
       " ('kitcheni_V', 10),\n",
       " ('visible_N', 10),\n",
       " ('hygienicthe_N', 10),\n",
       " ('travelingthe_N', 10),\n",
       " ('myeon_N', 10),\n",
       " ('goodconvenience_N', 10),\n",
       " ('footit_N', 10),\n",
       " ('gangbanger_N', 10),\n",
       " ('oldstyle_J', 10),\n",
       " ('pictureive_J', 10),\n",
       " ('bel_N', 10),\n",
       " ('restedthe_J', 10),\n",
       " ('tasting_N', 10),\n",
       " ('bedthanks_N', 10),\n",
       " ('gastardium_N', 10),\n",
       " ('political_J', 10),\n",
       " ('complexit_N', 10),\n",
       " ('st_R', 10),\n",
       " ('firstfloor_J', 10),\n",
       " ('stressful_N', 10),\n",
       " ('pinch_N', 10),\n",
       " ('firstaid_J', 10),\n",
       " ('breakfastyou_N', 10),\n",
       " ('againhowever_R', 10),\n",
       " ('hostmy_N', 10),\n",
       " ('picturesbut_N', 10),\n",
       " ('louder_R', 10),\n",
       " ('hed_J', 10),\n",
       " ('smellthe_N', 10),\n",
       " ('availablei_N', 10),\n",
       " ('welltodo_J', 10),\n",
       " ('acommodating_V', 10),\n",
       " ('rlly_R', 10),\n",
       " ('washi_N', 10),\n",
       " ('arrivedit_N', 10),\n",
       " ('emphasize_N', 10),\n",
       " ('schedulethe_J', 10),\n",
       " ('twoyearold_N', 10),\n",
       " ('lodgingsi_J', 10),\n",
       " ('goodhah_N', 10),\n",
       " ('updating_J', 10),\n",
       " ('floorthere_J', 10),\n",
       " ('pound_V', 10),\n",
       " ('endlessly_R', 10),\n",
       " ('thug_N', 10),\n",
       " ('goodas_J', 10),\n",
       " ('timeanyway_N', 10),\n",
       " ('sunbathe_V', 10),\n",
       " ('armchair_N', 10),\n",
       " ('progovernment_N', 10),\n",
       " ('derbay_R', 10),\n",
       " ('friendlyhe_N', 10),\n",
       " ('daysif_V', 10),\n",
       " ('getgo_N', 10),\n",
       " ('goodthere_N', 10),\n",
       " ('grant_N', 10),\n",
       " ('supermart_J', 10),\n",
       " ('skinny_J', 10),\n",
       " ('sunnys_R', 10),\n",
       " ('tidyit_J', 10),\n",
       " ('goodmost_N', 10),\n",
       " ('brisk_N', 10),\n",
       " ('wok_N', 10),\n",
       " ('carve_V', 10),\n",
       " ('wheel_V', 10),\n",
       " ('communicationits_N', 10),\n",
       " ('impressivei_N', 10),\n",
       " ('whirlpool_J', 10),\n",
       " ('expensivei_N', 10),\n",
       " ('minjeong_J', 10),\n",
       " ('friendsit_V', 10),\n",
       " ('fr_V', 10),\n",
       " ('hastily_R', 10),\n",
       " ('scarce_N', 10),\n",
       " ('naomi_N', 10),\n",
       " ('stored_J', 10),\n",
       " ('cube_J', 10),\n",
       " ('roadthere_R', 10),\n",
       " ('greatness_N', 10),\n",
       " ('angler_N', 10),\n",
       " ('daysim_N', 10),\n",
       " ('messenger_R', 10),\n",
       " ('circlethe_N', 10),\n",
       " ('wait_R', 10),\n",
       " ('chinese_V', 10),\n",
       " ('oyster_N', 10),\n",
       " ('postoffice_N', 10),\n",
       " ('cigarette_V', 10),\n",
       " ('full_V', 10),\n",
       " ('pricetheres_N', 10),\n",
       " ('translated_J', 10),\n",
       " ('squat_N', 10),\n",
       " ('contentment_N', 10),\n",
       " ('questionthe_N', 10),\n",
       " ('homein_N', 10),\n",
       " ('fthe_N', 10),\n",
       " ('plunger_N', 10),\n",
       " ('interiorthere_R', 10),\n",
       " ('joohee_N', 10),\n",
       " ('hospitability_N', 10),\n",
       " ('shutter_N', 10),\n",
       " ('memo_V', 10),\n",
       " ('anythingits_N', 10),\n",
       " ('tout_N', 10),\n",
       " ('kingsize_V', 10),\n",
       " ('defect_V', 10),\n",
       " ('ying_V', 10),\n",
       " ('backward_R', 10),\n",
       " ('taiwanese_V', 10),\n",
       " ('comply_V', 10),\n",
       " ('convenienton_N', 10),\n",
       " ('neatyou_N', 10),\n",
       " ('stopand_N', 10),\n",
       " ('charles_V', 10),\n",
       " ('nightin_N', 10),\n",
       " ('thoughti_V', 10),\n",
       " ('hotit_J', 10),\n",
       " ('aswell_V', 10),\n",
       " ('goodalthough_N', 10),\n",
       " ('minkyung_N', 10),\n",
       " ('farther_V', 10),\n",
       " ('bestthanks_N', 10),\n",
       " ('minutesif_J', 10),\n",
       " ('stayathome_J', 10),\n",
       " ('renovate_N', 10),\n",
       " ('taxiits_N', 10),\n",
       " ('hoop_N', 10),\n",
       " ('slam_N', 10),\n",
       " ('everthing_N', 10),\n",
       " ('dae_V', 10),\n",
       " ('comfortablynext_J', 10),\n",
       " ('notified_J', 10),\n",
       " ('dolce_N', 10),\n",
       " ('rink_N', 10),\n",
       " ('comm_N', 10),\n",
       " ('shopkeeper_J', 10),\n",
       " ('bathroomi_V', 10),\n",
       " ('nightthanks_N', 10),\n",
       " ('kindwhen_V', 10),\n",
       " ('gyeongjus_J', 10),\n",
       " ('fungus_N', 10),\n",
       " ('accommodationim_N', 10),\n",
       " ('attractionsi_N', 10),\n",
       " ('sunflower_J', 10),\n",
       " ('taiwanesei_N', 10),\n",
       " ('moreit_N', 10),\n",
       " ('dirtyi_N', 10),\n",
       " ('presumptuous_J', 10),\n",
       " ('nowits_N', 10),\n",
       " ('perfectits_V', 10),\n",
       " ('roomeverything_V', 10),\n",
       " ('outthere_R', 10),\n",
       " ('wet_R', 10),\n",
       " ('decoratedthe_J', 10),\n",
       " ('unnoticed_J', 10),\n",
       " ('walkingthe_J', 10),\n",
       " ('stentiars_N', 10),\n",
       " ('dispose_N', 10),\n",
       " ('chromecast_N', 10),\n",
       " ('uncles_J', 10),\n",
       " ('vod_N', 10),\n",
       " ('firstits_N', 10),\n",
       " ('handled_J', 10),\n",
       " ('kidding_N', 10),\n",
       " ('familiesthe_J', 10),\n",
       " ('antiquity_N', 10),\n",
       " ('kb_N', 10),\n",
       " ('comfortableit_R', 10),\n",
       " ('latei_R', 10),\n",
       " ('hubbub_N', 10),\n",
       " ('sweat_J', 10),\n",
       " ('juice_V', 10),\n",
       " ('toits_N', 10),\n",
       " ('insta_V', 10),\n",
       " ('reallyit_N', 10),\n",
       " ('shining_N', 10),\n",
       " ('ahold_J', 10),\n",
       " ('coincide_V', 10),\n",
       " ('daysand_N', 10),\n",
       " ('satisfiedthank_V', 10),\n",
       " ('therapy_N', 10),\n",
       " ('afterthe_J', 10),\n",
       " ('himits_N', 10),\n",
       " ('downgrade_V', 10),\n",
       " ('morningi_R', 10),\n",
       " ('costco_J', 10),\n",
       " ('beautifulthe_V', 10),\n",
       " ('seveneleven_R', 10),\n",
       " ('againits_V', 10),\n",
       " ('cappuccino_N', 10),\n",
       " ('curfew_V', 10),\n",
       " ('youthful_N', 10),\n",
       " ('dishesthe_N', 10),\n",
       " ('heartfelt_V', 10),\n",
       " ('josephine_N', 10),\n",
       " ('teresa_V', 10),\n",
       " ('accomplish_J', 10),\n",
       " ('nostalgia_J', 10),\n",
       " ('ali_N', 10),\n",
       " ('niceeverything_V', 10),\n",
       " ('bc_V', 10),\n",
       " ('srt_N', 10),\n",
       " ('rack_R', 10),\n",
       " ('heri_J', 10),\n",
       " ('neigbourhood_N', 10),\n",
       " ('conveniency_N', 10),\n",
       " ('deuks_N', 10),\n",
       " ('sub_V', 10),\n",
       " ('greatfirst_J', 10),\n",
       " ('wetroom_N', 10),\n",
       " ('jh_J', 10),\n",
       " ('leftthe_N', 10),\n",
       " ('kindbut_V', 10),\n",
       " ('comfortableand_V', 10),\n",
       " ('wellbehaved_V', 10),\n",
       " ('fetched_J', 10),\n",
       " ('convenienteverything_V', 10),\n",
       " ('recognise_V', 10),\n",
       " ('populate_V', 10),\n",
       " ('litter_N', 10),\n",
       " ('seal_J', 10),\n",
       " ('appart_N', 10),\n",
       " ('miyoung_V', 10),\n",
       " ('westin_J', 10),\n",
       " ('dynamic_N', 10),\n",
       " ('neighboorhood_J', 10),\n",
       " ('wellexplained_V', 10),\n",
       " ('mens_V', 10),\n",
       " ('everythings_V', 10),\n",
       " ('matilda_N', 10),\n",
       " ('width_J', 10),\n",
       " ('globe_N', 10),\n",
       " ('wendys_J', 10),\n",
       " ('areumsol_R', 10),\n",
       " ('nang_N', 10),\n",
       " ('mers_N', 10),\n",
       " ('carthere_R', 10),\n",
       " ('stiff_V', 10),\n",
       " ('writes_N', 10),\n",
       " ('posted_J', 10),\n",
       " ('inventory_N', 10),\n",
       " ('greatclean_J', 10),\n",
       " ('sympatric_J', 10),\n",
       " ('respite_N', 10),\n",
       " ('benny_R', 10),\n",
       " ('mistaken_J', 10),\n",
       " ('difficulties_V', 10),\n",
       " ('niceit_V', 10),\n",
       " ('aisle_N', 10),\n",
       " ('watermelon_J', 10),\n",
       " ('sweety_N', 10),\n",
       " ('tadpole_N', 10),\n",
       " ('epitome_J', 10),\n",
       " ('preparedit_V', 10),\n",
       " ('cozyclean_J', 10),\n",
       " ('permanently_R', 10),\n",
       " ('mcd_N', 10),\n",
       " ('muststay_N', 10),\n",
       " ('lynes_N', 10),\n",
       " ('usefulthe_J', 10),\n",
       " ('longi_V', 10),\n",
       " ('morningthis_N', 10),\n",
       " ('everyhing_V', 10),\n",
       " ('floortheres_N', 10),\n",
       " ('fo_J', 10),\n",
       " ('hardness_N', 10),\n",
       " ('cleanwarm_N', 10),\n",
       " ('girli_N', 10),\n",
       " ('instructionsdirections_N', 10),\n",
       " ('ocd_J', 10),\n",
       " ('tipps_N', 10),\n",
       " ('onethere_R', 10),\n",
       " ('nightits_V', 10),\n",
       " ('pray_V', 10),\n",
       " ('commanding_N', 10),\n",
       " ('helpfuli_V', 10),\n",
       " ('warmful_J', 10),\n",
       " ('overseas_N', 10),\n",
       " ('houseon_N', 10),\n",
       " ('argument_N', 10),\n",
       " ('fourperson_J', 10),\n",
       " ('nicelooking_J', 10),\n",
       " ('bread_R', 10),\n",
       " ('nearbyanyway_R', 10),\n",
       " ('equation_N', 10),\n",
       " ('eightmonthold_V', 10),\n",
       " ('junjang_N', 10),\n",
       " ('awsome_V', 10),\n",
       " ('responsethe_J', 10),\n",
       " ('sooyoung_N', 10),\n",
       " ('narrowthe_J', 10),\n",
       " ('rv_N', 10),\n",
       " ('cleaneri_N', 10),\n",
       " ('againfor_J', 10),\n",
       " ('exclaim_V', 10),\n",
       " ('deficiency_N', 10),\n",
       " ('perfectif_N', 10),\n",
       " ('allthere_R', 10),\n",
       " ('ref_V', 10),\n",
       " ('populated_J', 10),\n",
       " ('silicon_N', 10),\n",
       " ('upon_J', 10),\n",
       " ('lobby_R', 10),\n",
       " ('freinds_N', 10),\n",
       " ('hare_N', 10),\n",
       " ('coffees_V', 10),\n",
       " ('switched_J', 10),\n",
       " ('zonei_N', 10),\n",
       " ('auxiliary_N', 10),\n",
       " ('niceim_R', 10),\n",
       " ('myselfthe_N', 10),\n",
       " ('suppliesi_N', 10),\n",
       " ('cane_N', 10),\n",
       " ('playthe_J', 10),\n",
       " ('stationconvenient_N', 10),\n",
       " ('aunty_R', 10),\n",
       " ('render_N', 10),\n",
       " ('noticeably_R', 10),\n",
       " ('matt_V', 10),\n",
       " ('hae_V', 10),\n",
       " ('freethe_J', 10),\n",
       " ('neednt_J', 10),\n",
       " ('coldhot_J', 10),\n",
       " ('directionsinstructions_N', 10),\n",
       " ('proactive_V', 10),\n",
       " ('sitethe_N', 10),\n",
       " ('environmentits_N', 10),\n",
       " ('stories_V', 10),\n",
       " ('toothbrushit_N', 10),\n",
       " ('buffet_J', 10),\n",
       " ('anyways_V', 10),\n",
       " ('appliancesthe_N', 10),\n",
       " ('kindhe_V', 10),\n",
       " ('departed_J', 10),\n",
       " ('cattle_N', 10),\n",
       " ('victim_N', 10),\n",
       " ('temperamental_J', 10),\n",
       " ('chatter_N', 10),\n",
       " ('youthis_N', 10),\n",
       " ('litre_N', 10),\n",
       " ('baik_N', 10),\n",
       " ('satisfiedif_V', 10),\n",
       " ('dreamer_N', 10),\n",
       " ('solid_N', 10),\n",
       " ('combined_J', 10),\n",
       " ('este_N', 10),\n",
       " ('viewi_J', 10),\n",
       " ('roar_V', 10),\n",
       " ('goodto_N', 10),\n",
       " ('tooit_V', 10),\n",
       " ('hugh_N', 10),\n",
       " ('morninghaha_N', 10),\n",
       " ('itthats_N', 10),\n",
       " ('vomit_V', 10),\n",
       " ('choiceits_N', 10),\n",
       " ('horizon_J', 10),\n",
       " ('fresher_R', 10),\n",
       " ('ventilate_J', 10),\n",
       " ('bos_J', 10),\n",
       " ('juan_J', 10),\n",
       " ('unrivaled_J', 10),\n",
       " ('optimal_N', 10),\n",
       " ('widethe_J', 10),\n",
       " ('accommodationthis_J', 10),\n",
       " ('rag_N', 10),\n",
       " ('cause_R', 10),\n",
       " ('haeji_N', 10),\n",
       " ('chuchun_N', 10),\n",
       " ('goodin_J', 10),\n",
       " ('absentminded_V', 10),\n",
       " ('image_V', 10),\n",
       " ('jian_N', 10),\n",
       " ('taxiit_N', 10),\n",
       " ('traveler_J', 10),\n",
       " ('everyones_V', 10),\n",
       " ('accessiblethe_N', 10),\n",
       " ('grocer_N', 10),\n",
       " ('past_R', 10),\n",
       " ('toomy_J', 10),\n",
       " ('pokemon_N', 10),\n",
       " ('sexually_R', 10),\n",
       " ('upbut_J', 10),\n",
       " ('minyoung_N', 10),\n",
       " ('taegyo_N', 10),\n",
       " ('marriott_N', 10),\n",
       " ('luggageit_N', 10),\n",
       " ('neihu_J', 10),\n",
       " ('fit_R', 10),\n",
       " ('broken_R', 10),\n",
       " ('seep_V', 10),\n",
       " ('selfie_V', 10),\n",
       " ('humble_V', 10),\n",
       " ('staygood_N', 10),\n",
       " ('digit_N', 10),\n",
       " ('againbe_N', 10),\n",
       " ('tide_R', 10),\n",
       " ('wth_N', 10),\n",
       " ('plc_N', 10),\n",
       " ('moderate_V', 10),\n",
       " ('locationnear_N', 10),\n",
       " ('deck_J', 10),\n",
       " ('sunburn_V', 10),\n",
       " ('daythere_N', 10),\n",
       " ('bossit_N', 10),\n",
       " ('bandage_N', 10),\n",
       " ('waterfall_V', 10),\n",
       " ('hourthe_J', 10),\n",
       " ('visiter_N', 10),\n",
       " ('making_J', 10),\n",
       " ('niceplease_N', 10),\n",
       " ('profile_V', 10),\n",
       " ('thai_V', 10),\n",
       " ('newthe_N', 10),\n",
       " ('long_N', 10),\n",
       " ('noisyit_J', 10),\n",
       " ('elin_V', 10),\n",
       " ('journeyit_N', 10),\n",
       " ('breakfastbut_N', 10),\n",
       " ('serene_V', 10),\n",
       " ('good_R', 10),\n",
       " ('onoff_R', 10),\n",
       " ('gyeonggi_J', 10),\n",
       " ('wii_J', 10),\n",
       " ('aloneit_N', 10),\n",
       " ('cleanlinessits_N', 10),\n",
       " ('upwhen_J', 10),\n",
       " ('eagle_N', 10),\n",
       " ('perilla_N', 10),\n",
       " ('pricehowever_N', 10),\n",
       " ('personalised_J', 10),\n",
       " ('dinnerware_V', 10),\n",
       " ('arround_N', 10),\n",
       " ('comfortablyif_J', 10),\n",
       " ('earlyits_N', 10),\n",
       " ('goodtraffic_N', 10),\n",
       " ('chancehaha_N', 10),\n",
       " ('comfortablethis_N', 10),\n",
       " ('touri_N', 10),\n",
       " ('cutethank_N', 10),\n",
       " ('breakfasti_R', 10),\n",
       " ('openly_R', 10),\n",
       " ('adaptable_J', 10),\n",
       " ('dale_J', 10),\n",
       " ('removal_N', 10),\n",
       " ('herethank_J', 10),\n",
       " ('compact_V', 10),\n",
       " ('quietlyi_J', 10),\n",
       " ('stationa_N', 10),\n",
       " ('warmthanks_N', 10),\n",
       " ('interrupt_J', 10),\n",
       " ('avi_N', 10),\n",
       " ('basket_V', 10),\n",
       " ('doorbut_N', 10),\n",
       " ('hooray_N', 10),\n",
       " ('rightit_N', 10),\n",
       " ('enoughthere_R', 10),\n",
       " ('scenerythe_J', 10),\n",
       " ('awkwardly_R', 10),\n",
       " ('maze_V', 10),\n",
       " ('umbrellathe_J', 10),\n",
       " ('restaurent_N', 10),\n",
       " ('uncluttered_J', 10),\n",
       " ('atmosphereits_N', 10),\n",
       " ('kindlyit_J', 10),\n",
       " ('album_J', 10),\n",
       " ('stationline_J', 10),\n",
       " ('america_R', 10),\n",
       " ('placenear_J', 10),\n",
       " ('jukjeon_N', 10),\n",
       " ('locatedits_V', 10),\n",
       " ('vibrate_V', 10),\n",
       " ('daysthanks_N', 10),\n",
       " ('hanyu_N', 10),\n",
       " ('lindas_N', 10),\n",
       " ('hinoki_N', 10),\n",
       " ('houseive_J', 10),\n",
       " ('easyit_N', 10),\n",
       " ('recomand_N', 10),\n",
       " ('gohaha_N', 10),\n",
       " ('hoti_J', 10),\n",
       " ('seol_N', 10),\n",
       " ('lotus_V', 10),\n",
       " ('neil_N', 10),\n",
       " ('forthe_J', 10),\n",
       " ('satisfiedthere_J', 10),\n",
       " ('lake_R', 10),\n",
       " ('freedom_J', 10),\n",
       " ('labeled_J', 10),\n",
       " ('enoughit_N', 10),\n",
       " ('euro_N', 10),\n",
       " ('hwanggeum_N', 10),\n",
       " ('core_V', 10),\n",
       " ('needing_J', 10),\n",
       " ('koreai_V', 10),\n",
       " ('plesant_J', 10),\n",
       " ('soojins_N', 10),\n",
       " ('insideand_N', 10),\n",
       " ('overlap_N', 10),\n",
       " ('toll_N', 10),\n",
       " ('warmim_N', 10),\n",
       " ('deliver_J', 10),\n",
       " ('welcomed_N', 10),\n",
       " ('dongseong_J', 10),\n",
       " ('den_N', 10),\n",
       " ('samsong_J', 10),\n",
       " ('roadthe_V', 10),\n",
       " ('personthe_J', 10),\n",
       " ('alternate_V', 10),\n",
       " ('occupy_N', 10),\n",
       " ('selfcheckout_N', 10),\n",
       " ('refrigeratorthe_J', 10),\n",
       " ('deliciousif_J', 10),\n",
       " ('et_R', 10),\n",
       " ('namu_J', 10),\n",
       " ('adorably_R', 10),\n",
       " ('refurbishment_N', 10),\n",
       " ('restyou_N', 10),\n",
       " ('frog_J', 10),\n",
       " ('freshness_J', 10),\n",
       " ('suk_V', 10),\n",
       " ('universityit_J', 10),\n",
       " ('australia_R', 10),\n",
       " ('upits_J', 10),\n",
       " ('zhou_N', 10),\n",
       " ('suprisingly_R', 10),\n",
       " ('patty_J', 10),\n",
       " ('equiped_R', 10),\n",
       " ('changmins_N', 10),\n",
       " ('drape_N', 10),\n",
       " ('kindlyi_J', 10),\n",
       " ('luna_R', 10),\n",
       " ('woodwork_N', 10),\n",
       " ('spicy_J', 10),\n",
       " ('itit_V', 10),\n",
       " ('coldness_J', 10),\n",
       " ('roomall_N', 10),\n",
       " ('vouch_J', 10),\n",
       " ('serviced_J', 10),\n",
       " ('trendy_R', 10),\n",
       " ('runner_N', 10),\n",
       " ('around_V', 10),\n",
       " ('kihan_N', 10),\n",
       " ('moonlight_J', 10),\n",
       " ('selfcheck_V', 10),\n",
       " ('homestyle_N', 10),\n",
       " ('homeit_R', 10),\n",
       " ('warmbut_N', 10),\n",
       " ('meati_N', 10),\n",
       " ('thoroughly_N', 10),\n",
       " ('gothere_J', 10),\n",
       " ('therewe_N', 10),\n",
       " ('breathing_N', 10),\n",
       " ('easly_R', 10),\n",
       " ('foe_N', 10),\n",
       " ('countryi_N', 10),\n",
       " ('rosys_J', 10),\n",
       " ('gamseong_J', 10),\n",
       " ('pmit_N', 10),\n",
       " ('goggles_N', 10),\n",
       " ('lightthe_N', 10),\n",
       " ('prearrival_N', 10),\n",
       " ('centipede_V', 10),\n",
       " ('unload_N', 10),\n",
       " ('roasted_J', 10),\n",
       " ('warmand_V', 10),\n",
       " ('ojukheon_J', 10),\n",
       " ('middlei_N', 10),\n",
       " ('strain_V', 10),\n",
       " ('jinbu_N', 10),\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(voca_freq_dic2.items(),key=lambda kv:kv[1],reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del voca_freq_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel.load('pass_10_iter_3000.lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pass_10_iter_3000.lda.id2word','rb') as fp:\n",
    "    id2word = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'room_N'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.id2token.get(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_wordid = []\n",
    "for k in range(K):\n",
    "    wid, p = zip(*ldamodel.get_topic_terms(k,topn=30))\n",
    "    aspect_wordid.append(wid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_keywords = []\n",
    "for kth_keys in aspect_wordid:\n",
    "    kth_keywords = []\n",
    "    for wid in kth_keys:\n",
    "        kth_keywords.append(id2word.id2token.get(wid))\n",
    "    aspect_keywords.append(kth_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aspect_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_terms(aspects, vocab_dict):\n",
    "    aspect_terms = []\n",
    "    w_notfound = []\n",
    "    \n",
    "    for aspect_kws in aspects:\n",
    "        aspect = []\n",
    "        for w in aspect_kws:\n",
    "            if w in vocab_dict:\n",
    "                aspect.append(w)\n",
    "            else:\n",
    "                w_notfound.append(w)\n",
    "        aspect_terms.append(aspect)\n",
    "    #We are only using one hotel review file, as we keep inceasing the number of files words not found will decrease.\n",
    "    # print \"Words not found in vocab:\", ' '.join(w_notfound)\n",
    "    return aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_aspect_terms(aspect_keywords,voca_freq_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_sq(a,b,c,d):\n",
    "    c1 = a\n",
    "    c2 = b - a\n",
    "    c3 = c - a\n",
    "    c4 = d - b - c + a\n",
    "    nc =  d\n",
    "    return nc * (c1*c4 - c2*c3) * (c1*c4 - c2*c3)/((c1+c3) * (c2+c4) * (c1+c2) * (c3+c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_sq_mat():\n",
    "    global aspect_words, aspect_sent, num_words\n",
    "    asp_rank = np.zeros(aspect_words.shape)\n",
    "    for i in range(len(aspect_terms)):\n",
    "        for j in range(len(vocab)):\n",
    "            asp_rank[i][j] = chi_sq(aspect_words[i][j], num_words[j], aspect_sent[i], len(sent))\n",
    "    return asp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_terms = get_aspect_terms(aspect_keywords,voca_freq_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 30, 30, 30, 29, 30]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len,aspect_terms)) # aspect keywords는 5번 aspect의 1단어빼고 voca_freq_dic2에 포함됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspect_segmentaion(review_dic,voca_freq_dic):\n",
    "    #INPUT\n",
    "    review_sent = [] # 문장, 단어단위로 토크나이징된 리뷰 담은 리스트\n",
    "    for rev_lst in review_dic.values():\n",
    "        for rev in rev_lst:\n",
    "            review_sent.append(rev[1])\n",
    "    \n",
    "    all_ratings = []\n",
    "    for rev_lst in review_dic.values():\n",
    "        for rev in rev_lst:\n",
    "            all_ratings.append(rev[0])\n",
    "\n",
    "    #selection threshold\n",
    "    p = 5\n",
    "    \n",
    "    #Iterations \n",
    "    # I = 10\n",
    "    I = 1\n",
    "\n",
    "#     #Create Vocabulary\n",
    "#     #review_sent, review_actual, only_sent = parse_to_sentence(reviews)\n",
    "#     #vocab, #vocab_dict = create_vocab(only_sent)\n",
    "\n",
    "    vocab = list(voca_freq_dic.keys())\n",
    "    #Assign a number corresponding to each word. Makes counting easier.\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab)))) # word를 key 로 word의 인덱스를 value로  \n",
    "\n",
    "    #Aspect Keywords\n",
    "    aspect_terms = get_aspect_terms(aspect_keywords,voca_freq_dic)\n",
    "\n",
    "#     label_text = \n",
    "    # print aspect_terms\n",
    "\n",
    "    #ALGORITHM\n",
    "    review_labels = []\n",
    "    k = len(aspect_terms) # k: 토픽 개수 10\n",
    "    v = len(vocab) # v: 단어 개수 18923\n",
    "    \n",
    "    aspect_words = np.zeros((k,v))\n",
    "    aspect_sent = np.zeros(k)\n",
    "    num_words = np.zeros(v)\n",
    "    #-----------------------------------------------------\n",
    "    for _ in tqdm.tqdm(range(I)):\n",
    "        for r in review_sent:\n",
    "            labels = []\n",
    "            for s in r:\n",
    "                count = np.zeros(len(aspect_terms)) # 한 문장에 대해 aspect keyword가 몇개씩있는지 카운트\n",
    "                \n",
    "                for i,a in enumerate(aspect_terms):\n",
    "                    for w in s:\n",
    "                        if w in vocab_dict:\n",
    "                            num_words[vocab_dict[w]] += 1\n",
    "                            if w in a:\n",
    "                                count[i] += 1\n",
    "\n",
    "                if max(count) > 0:\n",
    "                    la = np.where(np.max(count) == count)[0].tolist() # count 중 max인 aspect들의  인덱스 뽑아 리스트로\n",
    "                    \n",
    "                    labels.append(la)\n",
    "                    for idx in la:\n",
    "                        aspect_sent[idx] += 1\n",
    "                        for w in s:\n",
    "                            if w in vocab_dict:\n",
    "                                aspect_words[idx][vocab_dict[w]] += 1\n",
    "                else:\n",
    "                    labels.append([])\n",
    "                    \n",
    "            review_labels.append(labels)\n",
    "        \n",
    "#             aspect_w_rank = chi_sq_mat()\n",
    "#             new_labels = []\n",
    "#             for na in aspect_w_rank:\n",
    "#                 x = np.argsort(na)[::-1][:p]\n",
    "#                 new_labels.append(x)\n",
    "#                 for k,v in vocab_dict.items():\n",
    "#                     if vocab_dict[k] in x:\n",
    "#                         print(k)\n",
    "#             sys.exit()\n",
    "            \n",
    "    return review_labels,review_sent\n",
    "\n",
    "#     ratings_sentiment = []\n",
    "#     for r in review_actual:\n",
    "#         sentiment = []\n",
    "#         #aspect ratings based on sentiment\n",
    "#         for s in r:\n",
    "#             ss = sid.polarity_scores(s)\n",
    "#             sentiment.append(ss['compound'])\n",
    "#         ratings_sentiment.append(sentiment)\n",
    "\n",
    "#     #Aspect Ratings Per Review\n",
    "#     aspect_ratings = []\n",
    "#     for i,r in enumerate(review_labels):\n",
    "#         rating = np.zeros(7)\n",
    "#         count = np.zeros(7)\n",
    "#         rs = ratings_sentiment[i] \n",
    "#         for j,l in enumerate(r):\n",
    "#             for k in range(7):\n",
    "#                 if k in l:\n",
    "#                     rating[k] += rs[j]\n",
    "#             for k in range(7):\n",
    "#                 if count[k] != 0:\n",
    "#                     rating[k] /= count[k]\n",
    "#         #Map from -[-1,1] to [1,5]\n",
    "#         for k in range(7):\n",
    "#             if rating[k] != 0:\n",
    "#                 rating[k] = int(round((rating[k]+1)*5/2))\n",
    "#         aspect_ratings.append(rating)\n",
    "#     return aspect_ratings, all_ratings\n",
    "\n",
    "    # n = 0\n",
    "    # print review_actual[n], '\\n', review_labels[n]\n",
    "    # print ratings_sentiment[n], '\\n', aspect_ratings[n]\n",
    "    # print len(all_ratings), len(reviews), all_ratings[0]\n",
    "    # sys.exit()\n",
    "    # return aspect_ratings\n",
    "\n",
    "    # print sent[5:9], labels[5:9]\n",
    "    # print zip(actual_sent, labels)[:10]\n",
    "    # print zip(actual_sent, sentiment)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_word = []\n",
    "for k,rev_lst in review.items():\n",
    "    for rev in rev_lst:\n",
    "        for i,sent in enumerate(rev[1]):\n",
    "            sent_tmp =[]\n",
    "            for word in sent:\n",
    "                if word in voca_freq_dic2:\n",
    "                    sent_tmp.append(word)\n",
    "                else:\n",
    "                    omit_word.append(word)\n",
    "            rev[1][i] = sent_tmp\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "review_labels2,review_sents2 = aspect_segmentaion(review2,voca_freq_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_labels2 = np.asarray(review_labels2)\n",
    "review_sents2 = np.array(review_sents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('review_labels.lst','wb') as fp:\n",
    "#     pickle.dump(review_labels,fp)\n",
    "# with open('review_sents.lst','wb') as fp:\n",
    "#     pickle.dump(review_sent,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_labels2[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['room_N',\n",
       " 'spacious_J',\n",
       " 'spacious_J',\n",
       " 'bedroom_N',\n",
       " 'see_V',\n",
       " 'go_V',\n",
       " 'caught_J',\n",
       " 'typhoon_N',\n",
       " 'fortunately_R',\n",
       " 'room_N',\n",
       " 'occupy_V',\n",
       " 'doubledecked_J',\n",
       " 'windowsthe_N',\n",
       " 'room_N',\n",
       " 'modern_J',\n",
       " 'pretty_R',\n",
       " 'good_J']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sents2[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.43307602),\n",
       " (1, 0.043798342),\n",
       " (2, 0.30630082),\n",
       " (3, 0.13603733),\n",
       " (4, 0.02652961),\n",
       " (5, 0.054257885)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA 의 예측과 비교\n",
    "\n",
    "doc = review_sents2[1][0]\n",
    "bow = ldamodel.id2word.doc2bow(doc)\n",
    "ldamodel[bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리뷰에 대해 aspect별로 word-frequency matrix를 만들어주자( *W_d_ij* )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cnt = 0\n",
    "for rev_lst in review2.values():\n",
    "    review_cnt += len(rev_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5543"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744447072"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = review_cnt # 리뷰수\n",
    "K = len(aspect_terms) # aspect 수\n",
    "N = len(voca_freq_dic2) # 단어수\n",
    "D*K*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-ebe7ff6ec6bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'int16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# W = np.ndarray((D,K,N),dtype = 'int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = {} # K로 나눠 딕셔너리 만들자\n",
    "for i in range(K):\n",
    "    W['w_'+str(i)] = np.ndarray((D,N),dtype = 'int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w_0': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16),\n",
       " 'w_1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16),\n",
       " 'w_2': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16),\n",
       " 'w_3': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16),\n",
       " 'w_4': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16),\n",
       " 'w_5': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16)}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kth_count(sent_labels, sents,k,freq_dic_kth):\n",
    "    for idx,label in enumerate(sent_labels):\n",
    "        if k in label: # kth aspect이면\n",
    "            for word in sents[idx]:\n",
    "                if word in freq_dic_kth:\n",
    "                    freq_dic_kth[word] += 1\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "\n",
    "def make_kth_mat(k):\n",
    "    global W,D # word freq 담을 전역변수 W. kth aspect 의 freq은 w_k (np.array)에 담는다/ 리뷰개수 D\n",
    "    for d in tqdm.tqdm(range(D)):# 리뷰개수만큼 돌면서\n",
    "        freq_dic_kth = dict.fromkeys(voca_freq_dic2.keys(),0) # kth freq dic 초기화\n",
    "        kth_count(review_labels2[d],review_sents2[d],k,freq_dic_kth) # freq_dic_kth 을 완성\n",
    "        words,freqs = zip(*sorted(freq_dic_kth.items(),key = lambda kv:kv[0])) # freq_dic_kth를 사전순으로 정렬해 단어와 freq를 각각 뽑는다\n",
    "        W['w_'+str(k)][d] = np.array(freqs,dtype='int16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5543/5543 [07:06<00:00, 12.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5543/5543 [06:59<00:00, 13.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5543/5543 [05:09<00:00, 17.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5543/5543 [04:11<00:00, 22.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5543/5543 [04:12<00:00, 21.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5543/5543 [04:10<00:00, 22.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for k in range(K):\n",
    "    make_kth_mat(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('W_6_100.mat','wb') as fp:\n",
    "#     pickle.dump(W,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('W_6_100.mat','rb') as fp:\n",
    "    W = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th aspect\n",
      "['room_N', 'house_N', 'nice_J', 'clean_J', 'really_R']\n",
      "sum of freq of words __ 38579 __\n",
      "1th aspect\n",
      "['station_N', 'convenient_N', 'restaurant_N', 'easy_J', 'area_N']\n",
      "sum of freq of words __ 22083 __\n",
      "2th aspect\n",
      "['place_N', 'great_J', 'good_J', 'location_N', 'stay_N']\n",
      "sum of freq of words __ 34118 __\n",
      "3th aspect\n",
      "['well_R', 'everything_N', 'need_V', 'small_J', 'people_N']\n",
      "sum of freq of words __ 15631 __\n",
      "4th aspect\n",
      "['take_V', 'check_N', 'check_V', 'wifi_N', 'arrive_V']\n",
      "sum of freq of words __ 7347 __\n",
      "5th aspect\n",
      "['host_N', 'get_V', 'kind_N', 'lot_N', 'provide_V']\n",
      "sum of freq of words __ 17506 __\n"
     ]
    }
   ],
   "source": [
    "for i in range(K): # k aspect별로 단어 freq의 합을 찍어보자\n",
    "    print('{}th aspect'.format(i))\n",
    "    print(aspect_keywords[i][:5])\n",
    "    print('sum of freq of words __',np.sum(W['w_'+str(i)]),'__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspect 구분없이 W 매트릭스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_all = np.ndarray((D,N),dtype = 'int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_count(sent_labels, sents, freq_dic):\n",
    "    for idx,label in enumerate(sent_labels):\n",
    "        for word in sents[idx]:\n",
    "            if word in freq_dic:\n",
    "                freq_dic[word] += 1\n",
    "            else:\n",
    "                continue        \n",
    "\n",
    "        \n",
    "def make_all_mat():\n",
    "    global W_all,D # word freq 담을 전역변수 W_all. 리뷰개수 D\n",
    "    for d in tqdm.tqdm(range(D)):# 리뷰개수만큼 돌면서\n",
    "        freq_dic = dict.fromkeys(voca_freq_dic2.keys(),0) # freq dic 초기화\n",
    "        all_count(review_labels2[d],review_sents2[d],freq_dic) # freq_dic 을 완성\n",
    "        words,freqs = zip(*sorted(freq_dic.items(),key = lambda kv:kv[0])) # freq_dic를 사전순으로 정렬해 단어와 freq를 각각 뽑는다\n",
    "        W_all[d] = np.array(freqs,dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5543/5543 [03:55<00:00, 23.52it/s]\n"
     ]
    }
   ],
   "source": [
    "make_all_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('W_all_100.mat','wb') as fp:\n",
    "    pickle.dump(W_all,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
