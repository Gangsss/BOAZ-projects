{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('tagsets')\n",
    "# nltk.download('stopword')\n",
    "# nltk.download('maxent_treebank_pos_tagger')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/chankoo/GitHub/BOAZ-projects/airbnb-NLP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./../airbnb-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review_jeju_143957.json',\n",
       " 'review_jeonju_13647.json',\n",
       " 'review_seoul_326990.json',\n",
       " 'review_seogwipo_51728.json',\n",
       " 'review_busan_70028.json',\n",
       " 'review_daegu_33689.json']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_lst = glob.glob('review_*_*.json')\n",
    "file_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = {}\n",
    "for file in file_lst:\n",
    "    with open(file,'r',encoding='utf-8') as fp:\n",
    "        review.update(json.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28853"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_en = {}\n",
    "for home_id,rev_lst in review.items():\n",
    "    review_en[home_id] = []\n",
    "    for rev in rev_lst:\n",
    "        if rev['language']=='en':\n",
    "            review_en[home_id].append([rev['rating'],rev['comments']])\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4,\n",
       "  \"It's a great experience staying at Hanuel's house. It's clean, kitchen is equipped with basic needs. Finding this place isn't hard as well, and it's really a good point that it's close to the airport.\\r\\n\\r\\nThere's some really good restaurant around the house. We had a good bbq duck meal and it's awesome!\\r\\n\\r\\nWould recommend this to anyone who like to visit Jeju!\"]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_en['10008511']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28853"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's a great experience staying at Hanuel's house.\",\n",
       " \"It's clean, kitchen is equipped with basic needs.\",\n",
       " \"Finding this place isn't hard as well, and it's really a good point that it's close to the airport.\",\n",
       " \"There's some really good restaurant around the house.\",\n",
       " \"We had a good bbq duck meal and it's awesome!\",\n",
       " 'Would recommend this to anyone who like to visit Jeju!']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(review_en['10008511'][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 114 ms, total: 29.4 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 리뷰별 문장단위 tokenizing\n",
    "for home_id,rev_lst in review_en.items():\n",
    "    for rev in rev_lst:\n",
    "        rev[1] = sent_tokenize(rev[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 538 ms, total: 2min 9s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# 문장별 단어단위 tokenizing\n",
    "for home_id,rev_lst in review_en.items(): \n",
    "    for rev in rev_lst:\n",
    "        tmp_lst = []\n",
    "        for sent in rev[1]:\n",
    "            word_lst = nltk.word_tokenize(sent)\n",
    "            tmp_lst.append(word_lst)\n",
    "        rev[1] = tmp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('experience', 'NN'),\n",
       " ('staying', 'VBG'),\n",
       " ('at', 'IN'),\n",
       " ('Hanuel', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('house', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(review_en['10008511'][0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28853/28853 [08:32<00:00, 56.35it/s] \n"
     ]
    }
   ],
   "source": [
    "for home_id,rev_lst in tqdm.tqdm(review_en.items()):\n",
    "    for rev in rev_lst:\n",
    "        tmp_lst = []\n",
    "        for sent_bow in rev[1]:\n",
    "            sent_pos = nltk.pos_tag(sent_bow)\n",
    "            tmp_lst.append(sent_pos)\n",
    "        rev[1] = tmp_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 구조를 보자\n",
    "\n",
    "- review_en == {home_id: [rev0, rev1, ...]}\n",
    "    - rev0 == [rating, [sent0, sent1, ...]]\n",
    "        - sent0 == [(word0,POS0),(word1,POS1), ...]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " [[('Kyungsoon', 'NNP'),\n",
       "   ('’', 'NNP'),\n",
       "   ('s', 'JJ'),\n",
       "   ('place', 'NN'),\n",
       "   ('is', 'VBZ'),\n",
       "   ('located', 'VBN'),\n",
       "   ('at', 'IN'),\n",
       "   ('a', 'DT'),\n",
       "   ('quiet', 'JJ'),\n",
       "   ('and', 'CC'),\n",
       "   ('peaceful', 'JJ'),\n",
       "   ('neighborhood', 'NN'),\n",
       "   ('not', 'RB'),\n",
       "   ('far', 'RB'),\n",
       "   ('from', 'IN'),\n",
       "   ('the', 'DT'),\n",
       "   ('city', 'NN'),\n",
       "   ('.', '.')],\n",
       "  [('Recommended', 'VBN'),\n",
       "   ('to', 'TO'),\n",
       "   ('those', 'DT'),\n",
       "   ('who', 'WP'),\n",
       "   ('have', 'VBP'),\n",
       "   ('rent', 'VBN'),\n",
       "   ('a', 'DT'),\n",
       "   ('car', 'NN'),\n",
       "   (',', ','),\n",
       "   ('the', 'DT'),\n",
       "   ('parking', 'VBG'),\n",
       "   ('area', 'NN'),\n",
       "   ('is', 'VBZ'),\n",
       "   ('spacious', 'JJ'),\n",
       "   ('.', '.')],\n",
       "  [('The', 'DT'),\n",
       "   ('house', 'NN'),\n",
       "   ('is', 'VBZ'),\n",
       "   ('clean', 'JJ'),\n",
       "   ('and', 'CC'),\n",
       "   ('comfortable', 'JJ'),\n",
       "   ('.', '.')],\n",
       "  [('We', 'PRP'),\n",
       "   ('are', 'VBP'),\n",
       "   ('a', 'DT'),\n",
       "   ('group', 'NN'),\n",
       "   ('of', 'IN'),\n",
       "   ('4', 'CD'),\n",
       "   (',', ','),\n",
       "   ('the', 'DT'),\n",
       "   ('house', 'NN'),\n",
       "   ('is', 'VBZ'),\n",
       "   ('just', 'RB'),\n",
       "   ('nice', 'JJ'),\n",
       "   ('for', 'IN'),\n",
       "   ('us', 'PRP'),\n",
       "   ('.', '.')],\n",
       "  [('The', 'DT'),\n",
       "   ('outside', 'JJ'),\n",
       "   ('view', 'NN'),\n",
       "   ('is', 'VBZ'),\n",
       "   ('beautiful', 'JJ'),\n",
       "   ('.', '.')]]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_en['10022410'][0] # rev0의 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unpacking과 zip 함수 이용해 rating과 review를 각각을 뽑아 리스트로 만들 수도 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_lst, rev_lst = zip(*review_en['10022410'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 5, 5, 5)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Kyungsoon', 'NNP'),\n",
       "  ('’', 'NNP'),\n",
       "  ('s', 'JJ'),\n",
       "  ('place', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('located', 'VBN'),\n",
       "  ('at', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('quiet', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('peaceful', 'JJ'),\n",
       "  ('neighborhood', 'NN'),\n",
       "  ('not', 'RB'),\n",
       "  ('far', 'RB'),\n",
       "  ('from', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('city', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Recommended', 'VBN'),\n",
       "  ('to', 'TO'),\n",
       "  ('those', 'DT'),\n",
       "  ('who', 'WP'),\n",
       "  ('have', 'VBP'),\n",
       "  ('rent', 'VBN'),\n",
       "  ('a', 'DT'),\n",
       "  ('car', 'NN'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('parking', 'VBG'),\n",
       "  ('area', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('spacious', 'JJ'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DT'),\n",
       "  ('house', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('clean', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('comfortable', 'JJ'),\n",
       "  ('.', '.')],\n",
       " [('We', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('group', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('4', 'CD'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('house', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('just', 'RB'),\n",
       "  ('nice', 'JJ'),\n",
       "  ('for', 'IN'),\n",
       "  ('us', 'PRP'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DT'),\n",
       "  ('outside', 'JJ'),\n",
       "  ('view', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('beautiful', 'JJ'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NNP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-88643b5f1196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrev_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtmp_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_sent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-88643b5f1196>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrev_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtmp_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_sent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0;31m#    find a match or you can't go any further\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1884\u001b[0;31m         \u001b[0mexceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1885\u001b[0m         \u001b[0msubstitutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMORPHOLOGICAL_SUBSTITUTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NNP'"
     ]
    }
   ],
   "source": [
    "for sent in rev_lst[0]:\n",
    "    tmp_sent = [lm.lemmatize(word[0],pos=word[1]) for word in sent]\n",
    "    sent = tmp_sent\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for home_id,rev_lst in tqdm.tqdm(review_en.items()):\n",
    "    for rev in rev_lst:\n",
    "        tmp_lst = []\n",
    "        for sent_bow in rev[1]:\n",
    "            sent_pos = nltk.pos_tag(sent_bow)\n",
    "            tmp_lst.append(sent_pos)\n",
    "        rev[1] = tmp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
