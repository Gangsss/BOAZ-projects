{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet,ElasticNetCV, Ridge, RidgeCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.chdir('/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 구글드라이브 DATA에 데이터있음\n",
    "with open('no_pos_review.json') as fp:\n",
    "    review = json.load(fp)\n",
    "with open('voca_freq_dic_new.json') as fp:\n",
    "    voca_freq_dic = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# key_lst = list(review.keys())\n",
    "# sampled_key_lst = key_lst[:3000]\n",
    "# review2 = {}\n",
    "# for k in sampled_key_lst:\n",
    "#     review2[k] = review[k]\n",
    "# len(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voca_freq_dic2 = {} # freq로 걸러서 일부 단어만 사용\n",
    "for k,v in voca_freq_dic.items():\n",
    "    if v>999:\n",
    "        voca_freq_dic2[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voca_freq_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sorted(voca_freq_dic2.items(),key=lambda kv:kv[1],reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA 결과(토픽별 키워드 리스트)를 aspect key words로 갖다써보자\n",
    "# 현재 불용어처리 등 덜된상태\n",
    "tmp = {0: [('station_N', 0.075440474),\n",
    "  ('convenient_N', 0.035710342),\n",
    "  ('location_N', 0.033328794),\n",
    "  ('walk_V', 0.03065599),\n",
    "  ('subway_N', 0.026240626),\n",
    "  ('place_N', 0.023897689),\n",
    "  ('minute_N', 0.023682337),\n",
    "  ('easy_J', 0.022524938),\n",
    "  ('locate_V', 0.019995727),\n",
    "  ('store_N', 0.019815892),\n",
    "  ('close_J', 0.019692997),\n",
    "  ('close_R', 0.019388903),\n",
    "  ('away_R', 0.01791159),\n",
    "  ('bus_N', 0.017175121),\n",
    "  ('airport_N', 0.0151694175),\n",
    "  ('convenience_N', 0.014715803),\n",
    "  ('also_R', 0.014201972),\n",
    "  ('walk_N', 0.013559201),\n",
    "  ('subway_J', 0.01225483),\n",
    "  ('apartment_N', 0.01212426),\n",
    "  ('convenient_J', 0.01193456),\n",
    "  ('go_V', 0.010800422),\n",
    "  ('distance_N', 0.010039834),\n",
    "  ('find_V', 0.009765462),\n",
    "  ('subway_R', 0.009758889),\n",
    "  ('take_V', 0.009583443),\n",
    "  ('get_V', 0.009291667),\n",
    "  ('line_N', 0.009158479),\n",
    "  ('restaurant_N', 0.0081279725),\n",
    "  ('house_N', 0.007849644)],\n",
    " 1: [('good_J', 0.09984607),\n",
    "  ('nice_J', 0.0702112),\n",
    "  ('location_N', 0.065345466),\n",
    "  ('really_R', 0.06501797),\n",
    "  ('place_N', 0.053646892),\n",
    "  ('comfortable_J', 0.033898752),\n",
    "  ('clean_J', 0.03378657),\n",
    "  ('stay_N', 0.025737181),\n",
    "  ('house_N', 0.025186999),\n",
    "  ('accommodation_N', 0.016483787),\n",
    "  ('apartment_N', 0.016000627),\n",
    "  ('perfect_J', 0.015435147),\n",
    "  ('space_N', 0.01426183),\n",
    "  ('bed_N', 0.0142121855),\n",
    "  ('wifi_N', 0.013773334),\n",
    "  ('landlord_N', 0.010759912),\n",
    "  ('perfect_N', 0.010674935),\n",
    "  ('amenity_N', 0.009882116),\n",
    "  ('new_J', 0.009253663),\n",
    "  ('tidy_N', 0.008537611),\n",
    "  ('quiet_J', 0.008063444),\n",
    "  ('lovely_R', 0.007641677),\n",
    "  ('central_J', 0.0074305693),\n",
    "  ('pretty_R', 0.007232856),\n",
    "  ('neat_N', 0.007133313),\n",
    "  ('egg_N', 0.007132264),\n",
    "  ('expect_V', 0.0070267115),\n",
    "  ('photo_N', 0.0068760742),\n",
    "  ('facility_N', 0.006667349),\n",
    "  ('felt_V', 0.006483669)],\n",
    " 2: [('area_N', 0.06683145),\n",
    "  ('night_N', 0.035611134),\n",
    "  ('quiet_J', 0.030158201),\n",
    "  ('quite_R', 0.023574363),\n",
    "  ('view_N', 0.023483817),\n",
    "  ('price_N', 0.022715302),\n",
    "  ('bit_N', 0.021813327),\n",
    "  ('see_V', 0.02036446),\n",
    "  ('neighborhood_N', 0.019612567),\n",
    "  ('right_J', 0.017915798),\n",
    "  ('little_J', 0.01292769),\n",
    "  ('city_N', 0.012332531),\n",
    "  ('part_N', 0.011145581),\n",
    "  ('apartment_N', 0.010512025),\n",
    "  ('beautiful_J', 0.010445903),\n",
    "  ('locate_V', 0.010315028),\n",
    "  ('park_N', 0.009846657),\n",
    "  ('building_N', 0.009445184),\n",
    "  ('issue_N', 0.008640434),\n",
    "  ('reply_V', 0.008343354),\n",
    "  ('soon_R', 0.008054228),\n",
    "  ('hard_J', 0.008007643),\n",
    "  ('window_N', 0.007892024),\n",
    "  ('also_R', 0.0077502076),\n",
    "  ('open_J', 0.007630731),\n",
    "  ('door_N', 0.007591834),\n",
    "  ('especially_R', 0.0068424055),\n",
    "  ('get_V', 0.006388696),\n",
    "  ('house_N', 0.006340781),\n",
    "  ('perfect_V', 0.0062577077)],\n",
    " 3: [('great_J', 0.15104426),\n",
    "  ('home_N', 0.03838182),\n",
    "  ('experience_N', 0.034535814),\n",
    "  ('thank_N', 0.03342067),\n",
    "  ('stay_N', 0.022656428),\n",
    "  ('make_V', 0.01760778),\n",
    "  ('thing_N', 0.01690892),\n",
    "  ('airbnb_N', 0.015427705),\n",
    "  ('place_V', 0.014597721),\n",
    "  ('feel_N', 0.014560298),\n",
    "  ('overall_J', 0.013511427),\n",
    "  ('super_J', 0.012852805),\n",
    "  ('apartment_N', 0.0127586955),\n",
    "  ('feel_V', 0.012492993),\n",
    "  ('instruction_N', 0.011910272),\n",
    "  ('know_V', 0.009106032),\n",
    "  ('flat_J', 0.009034321),\n",
    "  ('house_N', 0.008116479),\n",
    "  ('ive_J', 0.008065549),\n",
    "  ('anything_N', 0.0076171067),\n",
    "  ('meet_N', 0.007522718),\n",
    "  ('value_N', 0.0071481066),\n",
    "  ('book_V', 0.00696656),\n",
    "  ('choice_N', 0.0067781466),\n",
    "  ('different_J', 0.0067624864),\n",
    "  ('reply_N', 0.0065802587),\n",
    "  ('never_R', 0.0061996435),\n",
    "  ('hospitality_N', 0.006097631),\n",
    "  ('jay_N', 0.0060664965),\n",
    "  ('bad_J', 0.0058132866)],\n",
    " 4: [('room_N', 0.112217285),\n",
    "  ('well_R', 0.051788304),\n",
    "  ('everything_N', 0.051343787),\n",
    "  ('clean_J', 0.050989766),\n",
    "  ('house_N', 0.025484154),\n",
    "  ('apartment_N', 0.02400923),\n",
    "  ('need_V', 0.022365913),\n",
    "  ('clean_N', 0.021655692),\n",
    "  ('small_J', 0.02147159),\n",
    "  ('comfortable_J', 0.01924563),\n",
    "  ('need_N', 0.017338376),\n",
    "  ('cozy_N', 0.016669074),\n",
    "  ('big_J', 0.014753495),\n",
    "  ('spacious_J', 0.013613145),\n",
    "  ('bathroom_N', 0.012964344),\n",
    "  ('nice_N', 0.01125928),\n",
    "  ('people_N', 0.01100092),\n",
    "  ('picture_N', 0.010688399),\n",
    "  ('provide_V', 0.010524188),\n",
    "  ('warm_J', 0.00983317),\n",
    "  ('kitchen_N', 0.009782993),\n",
    "  ('clean_V', 0.009278437),\n",
    "  ('also_R', 0.008697552),\n",
    "  ('responsive_J', 0.008031375),\n",
    "  ('towel_N', 0.007448198),\n",
    "  ('large_J', 0.0072318553),\n",
    "  ('bed_V', 0.0071571474),\n",
    "  ('equip_V', 0.0070687374),\n",
    "  ('enough_R', 0.0065676877),\n",
    "  ('live_V', 0.006433929)],\n",
    " 5: [('even_R', 0.023927504),\n",
    "  ('floor_N', 0.020947738),\n",
    "  ('get_V', 0.016879946),\n",
    "  ('little_J', 0.01670006),\n",
    "  ('problem_N', 0.016578786),\n",
    "  ('water_N', 0.016478194),\n",
    "  ('exactly_R', 0.013305269),\n",
    "  ('extremely_R', 0.0122868465),\n",
    "  ('didnt_N', 0.011868971),\n",
    "  ('use_N', 0.01179084),\n",
    "  ('machine_N', 0.011563873),\n",
    "  ('show_V', 0.011448914),\n",
    "  ('night_N', 0.011121356),\n",
    "  ('wash_V', 0.010934781),\n",
    "  ('late_J', 0.010417275),\n",
    "  ('check_V', 0.010238513),\n",
    "  ('hot_J', 0.010211995),\n",
    "  ('use_V', 0.010035234),\n",
    "  ('however_R', 0.009700446),\n",
    "  ('arrive_V', 0.009524829),\n",
    "  ('accommodate_V', 0.009023434),\n",
    "  ('early_J', 0.0089837825),\n",
    "  ('also_R', 0.008448831),\n",
    "  ('air_N', 0.008398446),\n",
    "  ('check_N', 0.008317534),\n",
    "  ('still_R', 0.00801234),\n",
    "  ('leave_V', 0.007958689),\n",
    "  ('toilet_N', 0.0075545954),\n",
    "  ('bed_N', 0.0074843178),\n",
    "  ('find_V', 0.0071834484)],\n",
    " 6: [('day_N', 0.044497136),\n",
    "  ('make_V', 0.035028186),\n",
    "  ('time_N', 0.02947009),\n",
    "  ('friend_N', 0.023036933),\n",
    "  ('much_J', 0.022923442),\n",
    "  ('stay_V', 0.020721437),\n",
    "  ('help_N', 0.020701654),\n",
    "  ('love_V', 0.020222116),\n",
    "  ('trip_N', 0.018225666),\n",
    "  ('go_V', 0.018032515),\n",
    "  ('first_J', 0.017838366),\n",
    "  ('family_N', 0.016667131),\n",
    "  ('wonderful_J', 0.01531437),\n",
    "  ('sure_J', 0.012547571),\n",
    "  ('quickly_R', 0.012029172),\n",
    "  ('first_R', 0.010693285),\n",
    "  ('im_N', 0.010558216),\n",
    "  ('welcome_V', 0.010431975),\n",
    "  ('house_N', 0.009905076),\n",
    "  ('night_N', 0.009419678),\n",
    "  ('get_V', 0.009239833),\n",
    "  ('way_N', 0.009100049),\n",
    "  ('happy_J', 0.008998546),\n",
    "  ('even_R', 0.00883439),\n",
    "  ('luggage_N', 0.008800614),\n",
    "  ('recommended_J', 0.008401327),\n",
    "  ('respond_V', 0.008349242),\n",
    "  ('second_J', 0.008234377),\n",
    "  ('able_J', 0.008000888),\n",
    "  ('chance_N', 0.007491548)]\n",
    "       ,\n",
    " 7: [('lot_N', 0.043792848),\n",
    "  ('restaurant_N', 0.040813655),\n",
    "  ('many_J', 0.03109465),\n",
    "  ('food_N', 0.029509438),\n",
    "  ('good_J', 0.025894398),\n",
    "  ('take_V', 0.024536517),\n",
    "  ('min_N', 0.024025736),\n",
    "  ('street_N', 0.021218892),\n",
    "  ('shop_N', 0.020949543),\n",
    "  ('there_N', 0.015530614),\n",
    "  ('korean_J', 0.015057178),\n",
    "  ('person_N', 0.014282671),\n",
    "  ('shop_V', 0.0127358185),\n",
    "  ('studio_N', 0.012632791),\n",
    "  ('also_R', 0.012036752),\n",
    "  ('excellent_J', 0.011713238),\n",
    "  ('transportation_N', 0.011573859),\n",
    "  ('coffee_N', 0.011001995),\n",
    "  ('fantastic_J', 0.01008252),\n",
    "  ('nearby_R', 0.010082044),\n",
    "  ('local_J', 0.009666101),\n",
    "  ('warm_N', 0.009533902),\n",
    "  ('rest_N', 0.009117627),\n",
    "  ('care_N', 0.009051847),\n",
    "  ('bar_N', 0.008858041),\n",
    "  ('university_N', 0.0079645645),\n",
    "  ('traditional_J', 0.0073084603),\n",
    "  ('life_N', 0.007216505),\n",
    "  ('house_N', 0.0067656073),\n",
    "  ('thing_N', 0.0066509987)],\n",
    " 8: [('place_N', 0.09395834),\n",
    "  ('stay_V', 0.06079642),\n",
    "  ('stay_N', 0.05158205),\n",
    "  ('time_N', 0.04721144),\n",
    "  ('recommend_V', 0.041916873),\n",
    "  ('come_V', 0.03651728),\n",
    "  ('definitely_R', 0.036476232),\n",
    "  ('next_J', 0.03116234),\n",
    "  ('back_R', 0.029059581),\n",
    "  ('go_V', 0.023483075),\n",
    "  ('thanks_N', 0.019712204),\n",
    "  ('want_V', 0.019274745),\n",
    "  ('visit_N', 0.01906872),\n",
    "  ('highly_R', 0.017565712),\n",
    "  ('enjoy_V', 0.01718251),\n",
    "  ('best_J', 0.010691537),\n",
    "  ('amaze_V', 0.010670577),\n",
    "  ('stay_J', 0.010333447),\n",
    "  ('house_N', 0.010283317),\n",
    "  ('apartment_N', 0.009439452),\n",
    "  ('stop_N', 0.009254608),\n",
    "  ('look_V', 0.008955529),\n",
    "  ('guesthouse_N', 0.0072605656),\n",
    "  ('anyone_N', 0.007109243),\n",
    "  ('youre_N', 0.0068305926),\n",
    "  ('trip_N', 0.006618274),\n",
    "  ('book_N', 0.006315217),\n",
    "  ('visit_V', 0.0062876446),\n",
    "  ('use_N', 0.0058828676),\n",
    "  ('week_N', 0.0058368403)],\n",
    " 9: [('host_N', 0.0983368),\n",
    "  ('kind_N', 0.034277067),\n",
    "  ('helpful_J', 0.025665222),\n",
    "  ('help_V', 0.022550533),\n",
    "  ('give_V', 0.020565689),\n",
    "  ('also_R', 0.020454295),\n",
    "  ('nice_J', 0.020182502),\n",
    "  ('really_R', 0.01883619),\n",
    "  ('provide_V', 0.018348224),\n",
    "  ('question_N', 0.017101107),\n",
    "  ('friendly_R', 0.01532856),\n",
    "  ('always_R', 0.014121552),\n",
    "  ('friendly_J', 0.013314891),\n",
    "  ('helpful_N', 0.012839154),\n",
    "  ('guest_N', 0.012607242),\n",
    "  ('owner_N', 0.011304215),\n",
    "  ('breakfast_N', 0.010966653),\n",
    "  ('even_R', 0.009854197),\n",
    "  ('recommend_J', 0.009247552),\n",
    "  ('quick_J', 0.009128347),\n",
    "  ('communication_N', 0.008465741),\n",
    "  ('meet_V', 0.007926063),\n",
    "  ('information_N', 0.007655206),\n",
    "  ('get_V', 0.007644172),\n",
    "  ('direction_N', 0.0075688995),\n",
    "  ('easy_J', 0.0075597554),\n",
    "  ('need_V', 0.006919648),\n",
    "  ('shopping_N', 0.0067448863),\n",
    "  ('free_J', 0.006327245),\n",
    "  ('staff_N', 0.005882458)]\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_words = {}\n",
    "for k in range(len(tmp)):\n",
    "    seed_words[k] = []\n",
    "    for idx,tpl in enumerate(tmp[k]):\n",
    "        seed_words[k].append( (tpl[0][:-2],tpl[1]) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aspect_keywords = []\n",
    "for i,k_words in seed_words.items():\n",
    "    keys,b = zip(*k_words)\n",
    "    aspect_keywords.append(keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_aspect_terms(aspects, vocab_dict):\n",
    "    aspect_terms = []\n",
    "    w_notfound = []\n",
    "    \n",
    "    for aspect_kws in aspects:\n",
    "        aspect = []\n",
    "        for w in aspect_kws:\n",
    "            if w in vocab_dict:\n",
    "                aspect.append(w)\n",
    "            else:\n",
    "                w_notfound.append(w)\n",
    "        aspect_terms.append(aspect)\n",
    "    #We are only using one hotel review file, as we keep inceasing the number of files words not found will decrease.\n",
    "    # print \"Words not found in vocab:\", ' '.join(w_notfound)\n",
    "    return aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chi_sq(a,b,c,d):\n",
    "    c1 = a\n",
    "    c2 = b - a\n",
    "    c3 = c - a\n",
    "    c4 = d - b - c + a\n",
    "    nc =  d\n",
    "    return nc * (c1*c4 - c2*c3) * (c1*c4 - c2*c3)/((c1+c3) * (c2+c4) * (c1+c2) * (c3+c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chi_sq_mat():\n",
    "    global aspect_words, aspect_sent, num_words\n",
    "    asp_rank = np.zeros(aspect_words.shape)\n",
    "    for i in range(len(aspect_terms)):\n",
    "        for j in range(len(vocab)):\n",
    "            asp_rank[i][j] = chi_sq(aspect_words[i][j], num_words[j], aspect_sent[i], len(sent))\n",
    "    return asp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aspect_terms = get_aspect_terms(aspect_keywords,voca_freq_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aspect_segmentaion(review_dic,voca_freq_dic):\n",
    "    #INPUT\n",
    "    review_sent = [] # 문장, 단어단위로 토크나이징된 리뷰 담은 리스트\n",
    "    for rev_lst in review_dic.values():\n",
    "        for rev in rev_lst:\n",
    "            review_sent.append(rev[1])\n",
    "    \n",
    "    all_ratings = []\n",
    "    for rev_lst in review_dic.values():\n",
    "        for rev in rev_lst:\n",
    "            all_ratings.append(rev[0])\n",
    "\n",
    "    #selection threshold\n",
    "    p = 5\n",
    "    \n",
    "    #Iterations \n",
    "    # I = 10\n",
    "    I = 1\n",
    "\n",
    "#     #Create Vocabulary\n",
    "#     #review_sent, review_actual, only_sent = parse_to_sentence(reviews)\n",
    "#     #vocab, #vocab_dict = create_vocab(only_sent)\n",
    "\n",
    "    vocab = list(voca_freq_dic.keys())\n",
    "    #Assign a number corresponding to each word. Makes counting easier.\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab)))) # word를 key 로 word의 인덱스를 value로  \n",
    "\n",
    "    #Aspect Keywords\n",
    "    aspect_terms = get_aspect_terms(aspect_keywords,voca_freq_dic)\n",
    "\n",
    "#     label_text = \n",
    "    # print aspect_terms\n",
    "\n",
    "    #ALGORITHM\n",
    "    review_labels = []\n",
    "    k = len(aspect_terms) # k: 토픽 개수 10\n",
    "    v = len(vocab) # v: 단어 개수 18923\n",
    "    \n",
    "    aspect_words = np.zeros((k,v))\n",
    "    aspect_sent = np.zeros(k)\n",
    "    num_words = np.zeros(v)\n",
    "    #-----------------------------------------------------\n",
    "    for _ in range(I):\n",
    "        # print(len(review_sent)) 리뷰개수 595387\n",
    "        for r in review_sent:\n",
    "            labels = []\n",
    "            for s in r:\n",
    "                count = np.zeros(len(aspect_terms)) # 한 문장에 대해 aspect keyword가 몇개씩있는지 카운트\n",
    "                \n",
    "                for i,a in enumerate(aspect_terms):\n",
    "                    for w in s:\n",
    "                        if w in vocab_dict:\n",
    "                            num_words[vocab_dict[w]] += 1\n",
    "                            if w in a:\n",
    "                                count[i] += 1\n",
    "\n",
    "                if max(count) > 0:\n",
    "                    la = np.where(np.max(count) == count)[0].tolist() # count 중 max인 aspect들의  인덱스 뽑아 리스트로\n",
    "                    \n",
    "                    labels.append(la)\n",
    "                    for idx in la:\n",
    "                        aspect_sent[idx] += 1\n",
    "                        for w in s:\n",
    "                            if w in vocab_dict:\n",
    "                                aspect_words[idx][vocab_dict[w]] += 1\n",
    "                else:\n",
    "                    labels.append([])\n",
    "                    \n",
    "            review_labels.append(labels)\n",
    "        \n",
    "#             aspect_w_rank = chi_sq_mat()\n",
    "#             new_labels = []\n",
    "#             for na in aspect_w_rank:\n",
    "#                 x = np.argsort(na)[::-1][:p]\n",
    "#                 new_labels.append(x)\n",
    "#                 for k,v in vocab_dict.items():\n",
    "#                     if vocab_dict[k] in x:\n",
    "#                         print(k)\n",
    "#             sys.exit()\n",
    "            \n",
    "    return review_labels,review_sent\n",
    "\n",
    "#     ratings_sentiment = []\n",
    "#     for r in review_actual:\n",
    "#         sentiment = []\n",
    "#         #aspect ratings based on sentiment\n",
    "#         for s in r:\n",
    "#             ss = sid.polarity_scores(s)\n",
    "#             sentiment.append(ss['compound'])\n",
    "#         ratings_sentiment.append(sentiment)\n",
    "\n",
    "#     #Aspect Ratings Per Review\n",
    "#     aspect_ratings = []\n",
    "#     for i,r in enumerate(review_labels):\n",
    "#         rating = np.zeros(7)\n",
    "#         count = np.zeros(7)\n",
    "#         rs = ratings_sentiment[i] \n",
    "#         for j,l in enumerate(r):\n",
    "#             for k in range(7):\n",
    "#                 if k in l:\n",
    "#                     rating[k] += rs[j]\n",
    "#             for k in range(7):\n",
    "#                 if count[k] != 0:\n",
    "#                     rating[k] /= count[k]\n",
    "#         #Map from -[-1,1] to [1,5]\n",
    "#         for k in range(7):\n",
    "#             if rating[k] != 0:\n",
    "#                 rating[k] = int(round((rating[k]+1)*5/2))\n",
    "#         aspect_ratings.append(rating)\n",
    "#     return aspect_ratings, all_ratings\n",
    "\n",
    "    # n = 0\n",
    "    # print review_actual[n], '\\n', review_labels[n]\n",
    "    # print ratings_sentiment[n], '\\n', aspect_ratings[n]\n",
    "    # print len(all_ratings), len(reviews), all_ratings[0]\n",
    "    # sys.exit()\n",
    "    # return aspect_ratings\n",
    "\n",
    "    # print sent[5:9], labels[5:9]\n",
    "    # print zip(actual_sent, labels)[:10]\n",
    "    # print zip(actual_sent, sentiment)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# omit_word = []\n",
    "# for k,rev_lst in review.items():\n",
    "#     for rev in rev_lst:\n",
    "#         for i,sent in enumerate(rev[1]):\n",
    "#             sent_tmp =[]\n",
    "#             for word in sent:\n",
    "#                 if word in voca_freq_dic2:\n",
    "#                     sent_tmp.append(word)\n",
    "#                 else:\n",
    "#                     omit_word.append(word)\n",
    "#             rev[1][i] = sent_tmp\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 36s, sys: 3.12 s, total: 2min 39s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "review_labels,review_sents = aspect_segmentaion(review,voca_freq_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# review_labels_np = []\n",
    "# for rev in review_labels:\n",
    "#     rev_np = []\n",
    "#     for sent in rev:\n",
    "#         rev_np.append(np.array(sent))\n",
    "#     review_labels_np.append(np.array(rev_np))\n",
    "# review_labels_np = np.array(review_labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# review_labels_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['room',\n",
       "  'spacious',\n",
       "  'spacious',\n",
       "  'bedroom',\n",
       "  'see',\n",
       "  'windowwhen',\n",
       "  'go',\n",
       "  'caught',\n",
       "  'typhoon',\n",
       "  'fortunately',\n",
       "  'room',\n",
       "  'occupy',\n",
       "  'doubledecked',\n",
       "  'windowsthe',\n",
       "  'room',\n",
       "  'modern',\n",
       "  'technologicaloverall',\n",
       "  'pretty',\n",
       "  'good']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('review_labels.dat','wb') as fp:\n",
    "#     review_labels.dump(fp)\n",
    "# with open('review_sents.dat','wb') as fp:\n",
    "#     review_sents.dump(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('review_labels.lst','rb') as fp:\n",
    "#     review_labels = np.load(fp)\n",
    "# with open('review_sents.lst','rb') as fp:\n",
    "#     review_sents = np.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_cnt = 0\n",
    "for rev_lst in review.values():\n",
    "    review_cnt += len(rev_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6858858240"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = review_cnt # 리뷰수\n",
    "K = len(aspect_terms) # aspect 수\n",
    "N = len(voca_freq_dic2) # 단어수\n",
    "D*K*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W = np.ndarray((D,K,N),dtype = 'int16') # 메모리에 다 안올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = {} # k로 나눠 딕셔너리 만들자\n",
    "for i in range(K):\n",
    "    W['w_'+str(i)] = np.ndarray((D,N),dtype = 'int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for d,rev in enumerate(review_labels):\n",
    "#     for sent_idx,sent_labels in enumerate(rev):\n",
    "#         for label in sent_labels:\n",
    "#             review_sents[d][sent_idx]\n",
    "#             W[d][label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595387"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multiprocessing 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kth_count(sent_labels, sents,k,freq_dic_kth):\n",
    "    for idx,label in enumerate(sent_labels):\n",
    "        if k in label: # kth aspect이면\n",
    "            for word in sents[idx]:\n",
    "                if word not in freq_dic_kth:\n",
    "                    continue\n",
    "                freq_dic_kth[word] += 1\n",
    "        \n",
    "\n",
    "def make_kth_mat(k):\n",
    "    global W,D # word freq 담을 전역변수 W. kth aspect 의 freq은 w_k (np.array)에 담는다/ 리뷰개수 D\n",
    "    for d in tqdm.tqdm(range(D)):# 리뷰개수만큼 돌면서\n",
    "        freq_dic_kth = dict.fromkeys(voca_freq_dic2.keys(),0) # kth freq dic 초기화\n",
    "        kth_count(review_labels[d],review_sents[d],k,freq_dic_kth) # freq_dic_kth 을 완성\n",
    "        words,freqs = zip(*sorted(freq_dic_kth.items(),key = lambda kv:kv[0])) # freq_dic_kth를 사전순으로 정렬해 단어와 freq를 각각 뽑는다\n",
    "        W['w_'+str(k)][d] = np.array(freqs,dtype='int16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 595387/595387 [09:09<00:00, 1082.77it/s]\n",
      "100%|██████████| 595387/595387 [09:03<00:00, 1096.33it/s]\n",
      "100%|██████████| 595387/595387 [09:06<00:00, 1089.28it/s]\n",
      "100%|██████████| 595387/595387 [09:06<00:00, 1090.11it/s]\n",
      "100%|██████████| 595387/595387 [09:07<00:00, 1088.24it/s]\n",
      "100%|██████████| 595387/595387 [09:07<00:00, 1088.38it/s]\n",
      "100%|██████████| 595387/595387 [09:08<00:00, 1085.13it/s]\n",
      "100%|██████████| 595387/595387 [09:08<00:00, 1085.14it/s]\n",
      "100%|██████████| 595387/595387 [09:06<00:00, 1089.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,10):\n",
    "    try:\n",
    "        make_kth_mat(k)\n",
    "    except Exception as e:\n",
    "        print(k)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595387, 1152)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W['w_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th sum of word freq: 2374935\n",
      "1 th sum of word freq: 2648937\n",
      "2 th sum of word freq: 1111194\n",
      "3 th sum of word freq: 1162124\n",
      "4 th sum of word freq: 2132182\n",
      "5 th sum of word freq: 985160\n",
      "6 th sum of word freq: 1636130\n",
      "7 th sum of word freq: 1148598\n",
      "8 th sum of word freq: 1882418\n",
      "9 th sum of word freq: 1604520\n"
     ]
    }
   ],
   "source": [
    "for k in range(K):\n",
    "    print(k,'th sum of word freq:', W['w_'+str(k)].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = []\n",
    "for k,rev_lst in review.items():\n",
    "    for rev in rev_lst:\n",
    "        ratings.append(rev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = np.asarray(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_models_dic = {}\n",
    "sent_words_dic = {}\n",
    "def sent_word_net(k,ratings):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(W['w_'+str(k)], ratings, test_size=0.3, random_state =0)\n",
    "    cv_model = ElasticNetCV(l1_ratio=[ .1, .5, .7, .9, .95, .99, 1], eps=0.001, n_alphas=100, fit_intercept=True, \n",
    "                        normalize=True, precompute='auto', max_iter=500, tol=0.0001, cv=5, \n",
    "                        copy_X=True, verbose=0, n_jobs=-1, positive=False, random_state=None, selection='cyclic')\n",
    "    cv_model.fit(x_train, y_train)\n",
    "    cv_models_dic[k] = cv_model\n",
    "    \n",
    "    model = ElasticNet(l1_ratio=cv_model.l1_ratio_, alpha = cv_model.alpha_, max_iter=cv_model.n_iter_, fit_intercept=True, normalize = True)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    print('\\n\\n\\n-------------{}th aspect model----------'.format(k))\n",
    "    print('model.coef_.sum():',model.coef_.sum())\n",
    "    print('model.intercept_:',model.intercept_)\n",
    "    print('r2_score',r2_score(y_test, model.predict(x_test)))\n",
    "    \n",
    "    sent_words = list(zip(sorted(voca_freq_dic2,key=lambda kv:kv[0]),model.coef_))\n",
    "    sent_words_dic[k] = sent_words\n",
    "    \n",
    "    del cv_model, model,sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "-------------0th aspect model----------\n",
      "model.coef_.sum(): -11.1748998141\n",
      "model.intercept_: 4.67437505106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [06:30<58:37, 390.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.0198915680302\n",
      "\n",
      "\n",
      "\n",
      "-------------1th aspect model----------\n",
      "model.coef_.sum(): -13.4850830552\n",
      "model.intercept_: 4.64317528962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [12:20<50:27, 378.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.0463675917675\n",
      "\n",
      "\n",
      "\n",
      "-------------2th aspect model----------\n",
      "model.coef_.sum(): -6.83188345878\n",
      "model.intercept_: 4.69980154422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [18:44<44:20, 380.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.0269383387692\n",
      "\n",
      "\n",
      "\n",
      "-------------3th aspect model----------\n",
      "model.coef_.sum(): -15.9268235985\n",
      "model.intercept_: 4.67522345651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [24:29<36:58, 369.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.0333407085659\n",
      "\n",
      "\n",
      "\n",
      "-------------4th aspect model----------\n",
      "model.coef_.sum(): -10.7408602429\n",
      "model.intercept_: 4.67523607569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [30:29<30:33, 366.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.0495564324443\n",
      "\n",
      "\n",
      "\n",
      "-------------5th aspect model----------\n",
      "model.coef_.sum(): -4.12394808815\n",
      "model.intercept_: 4.71354756958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [36:29<24:19, 364.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.0410443082443\n",
      "\n",
      "\n",
      "\n",
      "-------------6th aspect model----------\n",
      "model.coef_.sum(): -19.2127831244\n",
      "model.intercept_: 4.70661485134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [42:20<18:01, 360.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.288440433023\n",
      "\n",
      "\n",
      "\n",
      "-------------7th aspect model----------\n",
      "model.coef_.sum(): -11.4314910099\n",
      "model.intercept_: 4.6866225393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [48:21<12:01, 360.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.0145208003465\n",
      "\n",
      "\n",
      "\n",
      "-------------8th aspect model----------\n",
      "model.coef_.sum(): -18.7948363562\n",
      "model.intercept_: 4.63580885453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [54:16<05:58, 358.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.0430884135035\n",
      "\n",
      "\n",
      "\n",
      "-------------9th aspect model----------\n",
      "model.coef_.sum(): -20.7789670501\n",
      "model.intercept_: 4.69957979495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [1:00:11<00:00, 357.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.278972070901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm.tqdm(range(K)):\n",
    "    try:\n",
    "        sent_word_net(k,ratings)\n",
    "    except Exception as e:\n",
    "        print(k,'\\n',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cv_models.dic','wb') as fp:\n",
    "    pickle.dump(cv_models_dic,fp)\n",
    "with open('beta.dic','wb') as fp:\n",
    "    pickle.dump(sent_words_dic,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_model = cv_models_dic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.00000114\n",
      "Optimal l1_ratio: 0.900\n",
      "Number of iterations 28\n"
     ]
    }
   ],
   "source": [
    "print('Optimal alpha: %.8f'%cv_model.alpha_)\n",
    "print('Optimal l1_ratio: %.3f'%cv_model.l1_ratio_)\n",
    "print('Number of iterations %d'%cv_model.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.4048687666091917e-06, copy_X=True, fit_intercept=True,\n",
       "      l1_ratio=0.90000000000000002, max_iter=26, normalize=True,\n",
       "      positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ElasticNet(l1_ratio=cv_model.l1_ratio_, alpha = cv_model.alpha_, max_iter=cv_model.n_iter_, fit_intercept=True, normalize = True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.278015543607825"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6747102064131312"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019759182703572797"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.75733367,  4.70465171,  4.67471021, ...,  4.67471021,\n",
       "        4.67471021,  4.67471021])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test = {\"test\":y_test,\"predict\":model.predict(x_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test = pd.DataFrame(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test['residual'] = predict_test['predict'] - predict_test['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>test</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13674</th>\n",
       "      <td>1.538079</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.461921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>2.789356</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.210644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165292</th>\n",
       "      <td>3.365324</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.634676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82950</th>\n",
       "      <td>3.370824</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.629176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118533</th>\n",
       "      <td>3.390214</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.609786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45825</th>\n",
       "      <td>3.394983</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.605017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67419</th>\n",
       "      <td>3.397710</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.602290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110878</th>\n",
       "      <td>3.432840</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.567160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>3.453653</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.546347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78919</th>\n",
       "      <td>3.455779</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.544221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114218</th>\n",
       "      <td>3.479913</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.520087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12875</th>\n",
       "      <td>3.479949</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.520051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151363</th>\n",
       "      <td>3.510710</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.489290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74955</th>\n",
       "      <td>3.515832</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.484168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128355</th>\n",
       "      <td>3.557653</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.442347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123498</th>\n",
       "      <td>3.599749</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.400251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159767</th>\n",
       "      <td>3.630945</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.369055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87703</th>\n",
       "      <td>3.637009</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.362991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134033</th>\n",
       "      <td>3.641456</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.358544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145101</th>\n",
       "      <td>3.652293</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.347707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23548</th>\n",
       "      <td>3.669676</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.330324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60618</th>\n",
       "      <td>3.694105</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.305895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41243</th>\n",
       "      <td>3.695435</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.304565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129689</th>\n",
       "      <td>3.717341</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.282659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>3.719939</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.280061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134428</th>\n",
       "      <td>3.724425</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.275575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63018</th>\n",
       "      <td>3.734762</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.265238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160526</th>\n",
       "      <td>3.765202</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.234798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35979</th>\n",
       "      <td>3.780737</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.219263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136523</th>\n",
       "      <td>3.788747</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.211253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159285</th>\n",
       "      <td>4.788470</td>\n",
       "      <td>0</td>\n",
       "      <td>4.788470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48251</th>\n",
       "      <td>4.791050</td>\n",
       "      <td>0</td>\n",
       "      <td>4.791050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>4.792954</td>\n",
       "      <td>0</td>\n",
       "      <td>4.792954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159875</th>\n",
       "      <td>4.796115</td>\n",
       "      <td>0</td>\n",
       "      <td>4.796115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109189</th>\n",
       "      <td>4.797108</td>\n",
       "      <td>0</td>\n",
       "      <td>4.797108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178484</th>\n",
       "      <td>4.806192</td>\n",
       "      <td>0</td>\n",
       "      <td>4.806192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135420</th>\n",
       "      <td>4.806551</td>\n",
       "      <td>0</td>\n",
       "      <td>4.806551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137833</th>\n",
       "      <td>4.812403</td>\n",
       "      <td>0</td>\n",
       "      <td>4.812403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44422</th>\n",
       "      <td>4.823675</td>\n",
       "      <td>0</td>\n",
       "      <td>4.823675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76941</th>\n",
       "      <td>4.823832</td>\n",
       "      <td>0</td>\n",
       "      <td>4.823832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165400</th>\n",
       "      <td>4.824605</td>\n",
       "      <td>0</td>\n",
       "      <td>4.824605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25361</th>\n",
       "      <td>4.829101</td>\n",
       "      <td>0</td>\n",
       "      <td>4.829101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67852</th>\n",
       "      <td>4.836787</td>\n",
       "      <td>0</td>\n",
       "      <td>4.836787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155732</th>\n",
       "      <td>4.844303</td>\n",
       "      <td>0</td>\n",
       "      <td>4.844303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119121</th>\n",
       "      <td>4.844918</td>\n",
       "      <td>0</td>\n",
       "      <td>4.844918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93848</th>\n",
       "      <td>4.850185</td>\n",
       "      <td>0</td>\n",
       "      <td>4.850185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166131</th>\n",
       "      <td>4.855768</td>\n",
       "      <td>0</td>\n",
       "      <td>4.855768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136673</th>\n",
       "      <td>4.861601</td>\n",
       "      <td>0</td>\n",
       "      <td>4.861601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134797</th>\n",
       "      <td>4.865218</td>\n",
       "      <td>0</td>\n",
       "      <td>4.865218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42590</th>\n",
       "      <td>4.874481</td>\n",
       "      <td>0</td>\n",
       "      <td>4.874481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102167</th>\n",
       "      <td>4.896335</td>\n",
       "      <td>0</td>\n",
       "      <td>4.896335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98480</th>\n",
       "      <td>4.896953</td>\n",
       "      <td>0</td>\n",
       "      <td>4.896953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43073</th>\n",
       "      <td>4.924599</td>\n",
       "      <td>0</td>\n",
       "      <td>4.924599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158569</th>\n",
       "      <td>4.946725</td>\n",
       "      <td>0</td>\n",
       "      <td>4.946725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>4.963187</td>\n",
       "      <td>0</td>\n",
       "      <td>4.963187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167269</th>\n",
       "      <td>4.966029</td>\n",
       "      <td>0</td>\n",
       "      <td>4.966029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167629</th>\n",
       "      <td>4.971940</td>\n",
       "      <td>0</td>\n",
       "      <td>4.971940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58628</th>\n",
       "      <td>4.977697</td>\n",
       "      <td>0</td>\n",
       "      <td>4.977697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168995</th>\n",
       "      <td>5.102442</td>\n",
       "      <td>0</td>\n",
       "      <td>5.102442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31327</th>\n",
       "      <td>5.112590</td>\n",
       "      <td>0</td>\n",
       "      <td>5.112590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178617 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         predict  test  residual\n",
       "13674   1.538079     4 -2.461921\n",
       "2079    2.789356     5 -2.210644\n",
       "165292  3.365324     5 -1.634676\n",
       "82950   3.370824     5 -1.629176\n",
       "118533  3.390214     5 -1.609786\n",
       "45825   3.394983     5 -1.605017\n",
       "67419   3.397710     5 -1.602290\n",
       "110878  3.432840     5 -1.567160\n",
       "429     3.453653     5 -1.546347\n",
       "78919   3.455779     5 -1.544221\n",
       "114218  3.479913     5 -1.520087\n",
       "12875   3.479949     5 -1.520051\n",
       "151363  3.510710     5 -1.489290\n",
       "74955   3.515832     5 -1.484168\n",
       "128355  3.557653     5 -1.442347\n",
       "123498  3.599749     5 -1.400251\n",
       "159767  3.630945     5 -1.369055\n",
       "87703   3.637009     5 -1.362991\n",
       "134033  3.641456     5 -1.358544\n",
       "145101  3.652293     5 -1.347707\n",
       "23548   3.669676     5 -1.330324\n",
       "60618   3.694105     5 -1.305895\n",
       "41243   3.695435     5 -1.304565\n",
       "129689  3.717341     5 -1.282659\n",
       "258     3.719939     5 -1.280061\n",
       "134428  3.724425     5 -1.275575\n",
       "63018   3.734762     5 -1.265238\n",
       "160526  3.765202     5 -1.234798\n",
       "35979   3.780737     5 -1.219263\n",
       "136523  3.788747     5 -1.211253\n",
       "...          ...   ...       ...\n",
       "159285  4.788470     0  4.788470\n",
       "48251   4.791050     0  4.791050\n",
       "5671    4.792954     0  4.792954\n",
       "159875  4.796115     0  4.796115\n",
       "109189  4.797108     0  4.797108\n",
       "178484  4.806192     0  4.806192\n",
       "135420  4.806551     0  4.806551\n",
       "137833  4.812403     0  4.812403\n",
       "44422   4.823675     0  4.823675\n",
       "76941   4.823832     0  4.823832\n",
       "165400  4.824605     0  4.824605\n",
       "25361   4.829101     0  4.829101\n",
       "67852   4.836787     0  4.836787\n",
       "155732  4.844303     0  4.844303\n",
       "119121  4.844918     0  4.844918\n",
       "93848   4.850185     0  4.850185\n",
       "166131  4.855768     0  4.855768\n",
       "136673  4.861601     0  4.861601\n",
       "134797  4.865218     0  4.865218\n",
       "42590   4.874481     0  4.874481\n",
       "102167  4.896335     0  4.896335\n",
       "98480   4.896953     0  4.896953\n",
       "43073   4.924599     0  4.924599\n",
       "158569  4.946725     0  4.946725\n",
       "2522    4.963187     0  4.963187\n",
       "167269  4.966029     0  4.966029\n",
       "167629  4.971940     0  4.971940\n",
       "58628   4.977697     0  4.977697\n",
       "168995  5.102442     0  5.102442\n",
       "31327   5.112590     0  5.112590\n",
       "\n",
       "[178617 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test.sort_values(by='residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('day', 0.044497136),\n",
       " ('make', 0.035028186),\n",
       " ('time', 0.02947009),\n",
       " ('friend', 0.023036933),\n",
       " ('much', 0.022923442)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 6\n",
    "sent_words = sent_words_dic[k]\n",
    "seed_words[k][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hong', 0.21967889813108327),\n",
       " ('oil', 0.20137329542015558),\n",
       " ('size', 0.14454090376071344),\n",
       " ('wet', 0.13595728955468467),\n",
       " ('foreign', 0.13438119547216482),\n",
       " ('ill', 0.13349886850745674),\n",
       " ('spend', 0.13196868311332477),\n",
       " ('weak', 0.13039046473465088),\n",
       " ('paper', 0.12600920734151969),\n",
       " ('advantage', 0.12531296493500735),\n",
       " ('felt', 0.12106213499518764),\n",
       " ('noisy', 0.11791168035715156),\n",
       " ('wellequipped', 0.11300980655233092),\n",
       " ('woman', 0.11221368021581064),\n",
       " ('heavy', 0.11188265563555122),\n",
       " ('ideal', 0.10971643164880196),\n",
       " ('etc', 0.1085541989746004),\n",
       " ('rice', 0.10768799552788581),\n",
       " ('charm', 0.10696658105592005),\n",
       " ('perfect', 0.1030331185847778),\n",
       " ('limousine', 0.10168190401453285),\n",
       " ('chat', 0.095395069657455547),\n",
       " ('appreciate', 0.094009195938209777),\n",
       " ('high', 0.093482065837885805),\n",
       " ('put', 0.092287884400155284),\n",
       " ('dongdaegu', 0.090982095276629149),\n",
       " ('basic', 0.090980832757891067),\n",
       " ('prepared', 0.090913568728972355),\n",
       " ('shampoo', 0.090652881298879481),\n",
       " ('instruction', 0.088541313809268968)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sent_words,key=lambda kv:kv[1],reverse=True)[:30] # 긍정 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('comfortable', -3.5270652145420858),\n",
       " ('deal', -1.1183094506758524),\n",
       " ('advertise', -0.68115456102892025),\n",
       " ('dongdaemun', -0.52944011256314061),\n",
       " ('shower', -0.4633522209314847),\n",
       " ('beam', -0.40936643548831375),\n",
       " ('schedule', -0.39153808394585593),\n",
       " ('provide', -0.37201564529094366),\n",
       " ('inside', -0.36915005820969282),\n",
       " ('post', -0.36244630867979383),\n",
       " ('promptly', -0.35895404050073382),\n",
       " ('bed', -0.33756615435846249),\n",
       " ('glad', -0.32108970887461535),\n",
       " ('music', -0.30739944581977663),\n",
       " ('balcony', -0.29924252793083062),\n",
       " ('parent', -0.29666579553815059),\n",
       " ('memorable', -0.28695890023856796),\n",
       " ('doesnt', -0.28156630308955788),\n",
       " ('traditional', -0.25863572756085779),\n",
       " ('total', -0.24599006171929433),\n",
       " ('considerate', -0.24164786906480482),\n",
       " ('university', -0.23880055685560986),\n",
       " ('inquiry', -0.23761760350532793),\n",
       " ('fish', -0.23508020719973916),\n",
       " ('snack', -0.22870996115851716),\n",
       " ('wind', -0.22469337988896287),\n",
       " ('lucky', -0.21781733486346688),\n",
       " ('hostel', -0.21777303744163673),\n",
       " ('bus', -0.21429353318719882),\n",
       " ('cancel', -0.21152484944140876)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sent_words,key=lambda kv:kv[1],reverse=False)[:30] # 부정 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
